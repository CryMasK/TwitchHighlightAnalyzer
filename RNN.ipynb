{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:46:19.142007Z",
     "start_time": "2019-09-02T10:45:50.045655Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, SimpleRNN, Masking, TimeDistributed, LSTM\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T18:46:45.815141Z",
     "start_time": "2019-07-21T18:46:45.745166Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T11:51:54.238525Z",
     "start_time": "2019-08-21T11:51:54.229528Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../TwitchHighlightCrawler/vod/\" # const\n",
    "DUMMY_VALUE = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T16:30:58.652309Z",
     "start_time": "2019-08-12T16:30:55.954187Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.load('training_data-k8uc6gtfz5tul.npy')\n",
    "Y = np.load('training_label-k8uc6gtfz5tul.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:45:07.225228Z",
     "start_time": "2019-09-02T10:45:07.220222Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def stringToDateTime(str): # only parse twitch info format\n",
    "    str = (str[:19] + 'Z') if len(str) > 20 else str\n",
    "    return dt.datetime.strptime(str, '%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T19:18:37.100246Z",
     "start_time": "2019-08-12T17:04:23.879281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_2 (Masking)          (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, None, 1)           4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 01:04:24.592210 11348 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 811s 5s/step - loss: 1.1295\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 784s 5s/step - loss: 1.1192\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 782s 5s/step - loss: 1.0820\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 790s 5s/step - loss: 1.0549\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 793s 5s/step - loss: 1.0359\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 777s 5s/step - loss: 1.0469\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 811s 5s/step - loss: 1.0367\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 853s 5s/step - loss: 0.9932\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 838s 5s/step - loss: 0.9745\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 813s 5s/step - loss: 0.9862\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=DUMMY_VALUE, input_shape=(None, 2)))\n",
    "#model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(1, return_sequences=True, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy')\n",
    "#model.summary()\n",
    "model.fit(X, Y, epochs=10, batch_size=8)\n",
    "model.save('mmm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T11:42:48.758095Z",
     "start_time": "2019-08-02T11:42:48.498179Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 1000 arrays: [array([[0.51024308],\n       [0.3404787 ],\n       [0.07502523],\n       [0.26591401],\n       [0.2502586 ],\n       [0.28769308],\n       [0.43627578],\n       [0.19952613],\n       [0.87965262],\n       [0....",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cae4737ed1de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 训练模型，以 32 个样本为一个 batch 进行迭代\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 1000 arrays: [array([[0.51024308],\n       [0.3404787 ],\n       [0.07502523],\n       [0.26591401],\n       [0.2502586 ],\n       [0.28769308],\n       [0.43627578],\n       [0.19952613],\n       [0.87965262],\n       [0...."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "'''data = np.random.random((1000, 10))\n",
    "labels = np.random.randint(2, size=(1000, 1))'''\n",
    "data = []\n",
    "labels = []\n",
    "import random\n",
    "for i in range(1000):\n",
    "    data.append(np.random.random(10))\n",
    "    labels.append(random.randint(0,1))\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T09:58:48.801962Z",
     "start_time": "2019-08-03T09:58:48.792962Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.95156836, 0.5257626 ],\n",
       "        [0.00156089, 0.85387701],\n",
       "        [0.78281018, 0.73223741],\n",
       "        [0.37595671, 0.49269121],\n",
       "        [0.92361927, 0.67693445],\n",
       "        [0.9214292 , 0.72112536],\n",
       "        [0.66214929, 0.10112643],\n",
       "        [0.90462236, 0.31870872],\n",
       "        [0.15810725, 0.73876466],\n",
       "        [0.53127291, 0.89857455]],\n",
       "\n",
       "       [[0.95156836, 0.5257626 ],\n",
       "        [0.00156089, 0.85387701],\n",
       "        [0.78281018, 0.73223741],\n",
       "        [0.37595671, 0.49269121],\n",
       "        [0.92361927, 0.67693445],\n",
       "        [0.9214292 , 0.72112536],\n",
       "        [0.66214929, 0.10112643],\n",
       "        [0.90462236, 0.31870872],\n",
       "        [0.15810725, 0.73876466],\n",
       "        [0.53127291, 0.89857455]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data = np.array([])\n",
    "data = np.append(data, np.random.random((10, 2)), axis=0)\n",
    "#data = np.append(data, np.random.random((10, 2)), axis=0)\n",
    "#np.concatenate((data, np.random.random((1,10, 2))),axis=0 )\n",
    "np.random.random((10, 2))\n",
    "data'''\n",
    "import random\n",
    "d = []\n",
    "features = []\n",
    "for i in range(10):\n",
    "    feature = []\n",
    "    for j in range(2):\n",
    "        feature.append(random.random())\n",
    "    features.append(feature)\n",
    "    \n",
    "d.append(features)\n",
    "d.append(features)\n",
    "np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T11:52:06.094524Z",
     "start_time": "2019-08-21T11:51:54.240525Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0821 19:51:54.256520  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0821 19:51:54.494101  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0821 19:51:54.571093  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0821 19:51:54.920798  4772 deprecation.py:323] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0821 19:51:55.028765  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0821 19:51:55.047758  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0821 19:51:55.607579  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 0.7155 - acc: 0.5360\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6940 - acc: 0.5642\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6936 - acc: 0.5517\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6891 - acc: 0.5585\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6891 - acc: 0.5601\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6850 - acc: 0.5660\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6834 - acc: 0.5632\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6814 - acc: 0.5998\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6785 - acc: 0.5844\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.5918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a38b91470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成虚拟数据\n",
    "import random\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "max_seq_len = 0\n",
    "\n",
    "N = 10 # number of data\n",
    "\n",
    "dummy = -1\n",
    "for i in range(N):\n",
    "    length = random.randint(5,25)\n",
    "    if length > max_seq_len:\n",
    "        max_seq_len = length\n",
    "    #length = 10\n",
    "    data.append( np.random.random((length, 2))  )\n",
    "    labels.append( np.random.randint(2, size=(length, 1)) )\n",
    "#np.set_printoptions(threshold=False)\n",
    "\n",
    "Xpad = np.full((N, max_seq_len, 2), fill_value=dummy, dtype='float64')\n",
    "Ypad = np.full((N, max_seq_len, 1), fill_value=dummy, dtype='float64')\n",
    "for s, x in enumerate(data):\n",
    "    video_length = len(x)\n",
    "    Xpad[s, 0:video_length, :] = x\n",
    "for s, y in enumerate(labels):\n",
    "    video_length = len(y)\n",
    "    Ypad[s, 0:video_length, :] = y\n",
    "\n",
    "#data = np.array(data)\n",
    "#labels = np.array(labels)\n",
    "#print(data.shape)\n",
    "#print(labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "#input = Input(shape=(None, 2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=dummy, input_shape=(None, 2)))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(1, return_sequences=True, activation='sigmoid'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "'''data = []\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(Xpad)\n",
    "    print(data)'''\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "#model.fit(data, labels, epochs=10, batch_size=8)\n",
    "model.fit(Xpad, Ypad, epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T11:55:33.888120Z",
     "start_time": "2019-08-21T11:55:33.821142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[2, 5],\n",
      "        [3, 6],\n",
      "        [4, 8]]]), array([[[2, 5],\n",
      "        [3, 6]]])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,2) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-72f7ff146840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3,2) into shape (1)"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "\n",
    "'''import random\n",
    "features = []\n",
    "for i in range(10):\n",
    "    feature = []\n",
    "    for j in range(2):\n",
    "        feature.append(random.random())\n",
    "    features.append(feature)\n",
    "test.append(features)\n",
    "test1 = np.array(test)\n",
    "\n",
    "test = []\n",
    "features = []\n",
    "for i in range(6):\n",
    "    feature = []\n",
    "    for j in range(2):\n",
    "        feature.append(random.random())\n",
    "    features.append(feature)\n",
    "test.append(features)\n",
    "test2 = np.array(test)\n",
    "\n",
    "test = np.array(test)\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    for i in range(2):\n",
    "        print(model.predict(test, batch_size=8))'''\n",
    "\n",
    "'''test = np.array([ [[[2,5],[3,6],[4,8]]], [[[2,5],[3,6]]] ]) # 4維 沒用\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(model.predict(test[0], batch_size=8))'''\n",
    "\n",
    "'''a = np.array([[[2,5],[3,6],[4,8]]])\n",
    "b = np.array([[[2,5],[3,6]]])\n",
    "c = []\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "test = np.array(c) # 無解 這行出錯\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(model.predict(test[0], batch_size=8))'''\n",
    "\n",
    "'''test.append(np.random.random((10, 2)))\n",
    "test.append(np.random.random((6, 2)))\n",
    "#test = np.array(test)\n",
    "Tpad = np.full((2, 10, 2), fill_value=dummy, dtype='Float64')\n",
    "for s, t in enumerate(test):\n",
    "    video_length = len(t)\n",
    "    Tpad[s, 0:video_length, :] = t\n",
    "\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(model.predict(Tpad, batch_size=8))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T10:46:44.685317Z",
     "start_time": "2019-09-02T10:46:44.621338Z"
    },
    "code_folding": [
     258,
     311,
     346,
     350,
     352,
     358,
     363
    ]
   },
   "outputs": [],
   "source": [
    "def local_score(clipDataList, predict, numberOfPredictedFragment):\n",
    "    localPrecision = 0\n",
    "    localRecall = 0\n",
    "    \n",
    "    videoLength = len(predict)\n",
    "    \n",
    "    for clip in clipDataList:\n",
    "        recall = 0\n",
    "        overlapTime = 0 # for local recall computing\n",
    "\n",
    "        endOfClip = clip['offset'] + clip['duration'] # not real video end timeline point\n",
    "\n",
    "        for i in range(clip['offset'] - (MAX_CLIP_LENGTH-1), clip['offset'] - MIN_CLIP_LENGTH + 1): # (offset - 59) <= prediction <= (offset - 5) # eg. offset = 85, duration = 10, 26~80\n",
    "            if predict[i] and (i + predict[i]['duration']) > clip['offset']: # Simplify from (i + (predict[i]['duration']-1)) >= clip['offset']\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset'] # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip:\n",
    "                    overlap -= (endOfPrediction - endOfClip) # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'] - MIN_CLIP_LENGTH + 1, clip['offset']): # (offset - 4(less than MIN_CLIP_LENGTH)) <= prediction < offset # 81~84\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset']; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip: # predicted fragment is larger than clip\n",
    "                    overlap -= (endOfPrediction - endOfClip); # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'], endOfClip): # offset <= prediction < (offset + duration) # 85~94\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfClip - i; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction < endOfClip: # predicted fragment is smaller than clip\n",
    "                    overlap -= endOfClip - endOfPrediction\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        if overlapTime:\n",
    "            recall /= overlapTime\n",
    "            localRecall += recall\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if predict[i]: # check have predicted fragment\n",
    "            if len(predict[i]['precision']): # the fragment has overlap\n",
    "                precision = 0 # for local precision computing\n",
    "\n",
    "                for singlePrecisionValue in predict[i]['precision']:\n",
    "                    # local precision\n",
    "                    precision += singlePrecisionValue\n",
    "                precision /= len(predict[i]['precision'])\n",
    "\n",
    "                localPrecision += precision\n",
    "\n",
    "    localPrecision /= numberOfPredictedFragment\n",
    "    localRecall /= len(clipDataList)\n",
    "    F1 = (2 * localPrecision * localRecall) / (localPrecision + localRecall)\n",
    "    print(str(localPrecision) + ' ' + str(localRecall) + ' ' + str(F1))\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "    \n",
    "def macro_score(clipDataList, predict):\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    macroF1 = 0\n",
    "    \n",
    "    videoLength = len(predict)\n",
    "    \n",
    "    for clip in clipDataList:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        F1 = 0\n",
    "        \n",
    "        overlapTime = 0\n",
    "\n",
    "        endOfClip = clip['offset'] + clip['duration'] # not real video end timeline point\n",
    "\n",
    "        for i in range(clip['offset'] - (MAX_CLIP_LENGTH-1), clip['offset'] - MIN_CLIP_LENGTH + 1): # (offset - 59) <= prediction <= (offset - 5) # eg. offset = 85, duration = 10, 26~80\n",
    "            if predict[i] and (i + predict[i]['duration']) > clip['offset']: # Simplify from (i + (predict[i]['duration']-1)) >= clip['offset']\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset'] # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip:\n",
    "                    overlap -= (endOfPrediction - endOfClip) # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'] - MIN_CLIP_LENGTH + 1, clip['offset']): # (offset - 4(less than MIN_CLIP_LENGTH)) <= prediction < offset # 81~84\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset']; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip: # predicted fragment is larger than clip\n",
    "                    overlap -= (endOfPrediction - endOfClip); # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'], endOfClip): # offset <= prediction < (offset + duration) # 85~94\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfClip - i; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction < endOfClip: # predicted fragment is smaller than clip\n",
    "                    overlap -= endOfClip - endOfPrediction\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        if overlapTime:\n",
    "            precision /= overlapTime\n",
    "            recall /= overlapTime\n",
    "            F1 /= overlapTime\n",
    "            \n",
    "            macroPrecision += precision\n",
    "            macroRecall += recall\n",
    "            macroF1 += F1\n",
    "    \n",
    "    numberOfAnswer = len(clipDataList)\n",
    "    \n",
    "    macroPrecision /= numberOfAnswer\n",
    "    macroRecall /= numberOfAnswer\n",
    "    macroF1 /= numberOfAnswer  \n",
    "    print(str(macroPrecision) + ' ' + str(macroRecall) + ' ' + str(macroF1))\n",
    "    \n",
    "def K_simple_global_score(label, prediction): # use to evaluation training data\n",
    "    THRESHOLD = 0.5\n",
    "    \n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0\n",
    "    totalPredictionSeconds = 0\n",
    "    \n",
    "    length = len(label)\n",
    "    for i in range(length):\n",
    "        if label[i][0] == -1:\n",
    "            break\n",
    "            \n",
    "        if prediction[i][0] > THRESHOLD:\n",
    "            totalPredictionSeconds += 1\n",
    "            if label[i][0]:\n",
    "                totalClipSeconds += 1\n",
    "                overlap += 1\n",
    "        elif label[i][0]:\n",
    "            totalClipSeconds += 1\n",
    "            \n",
    "    precision = (overlap / totalPredictionSeconds) if totalPredictionSeconds > 0 else 0\n",
    "    recall = (overlap / totalClipSeconds) if totalClipSeconds > 0 else 0\n",
    "    F1 = ((2 * precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "            \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "\n",
    "def global_score(groundTruth, predict):\n",
    "    videoLength = len(groundTruth)\n",
    "    \n",
    "    # normal score\n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0 # WARNING!! we can count this value when computing local score\n",
    "    totalPredictionSeconds = 0\n",
    "    \n",
    "    # weighted score\n",
    "    weightedOverlap = 0\n",
    "    totalWeightedClipSeconds = 0 # WARNING!! we can count this value when computing local score\n",
    "    totalWeightedPredictionSeconds = 0\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if groundTruth[i]:\n",
    "            totalClipSeconds += 1\n",
    "            totalWeightedClipSeconds += groundTruth[i]\n",
    "            \n",
    "            if predict[i]:\n",
    "                totalPredictionSeconds += 1\n",
    "                totalWeightedPredictionSeconds += groundTruth[i]\n",
    "                \n",
    "                overlap += 1\n",
    "                weightedOverlap += groundTruth[i]\n",
    "        elif predict[i]:\n",
    "            totalPredictionSeconds += 1\n",
    "            totalWeightedPredictionSeconds += 1 # no clip on this second, so weight is 1\n",
    "                \n",
    "    precision = overlap / totalPredictionSeconds if totalPredictionSeconds > 0 else 0\n",
    "    recall = overlap / totalClipSeconds if totalClipSeconds > 0 else 0\n",
    "    F1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    weightedPrecision = weightedOverlap / totalWeightedPredictionSeconds if totalWeightedPredictionSeconds > 0 else 0\n",
    "    weightedRecall = weightedOverlap / totalWeightedClipSeconds if totalWeightedClipSeconds > 0 else 0\n",
    "    weightedF1 = (2 * weightedPrecision * weightedRecall) / (weightedPrecision + weightedRecall) if (weightedPrecision + weightedRecall) > 0 else 0\n",
    "    \n",
    "    #print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "    #print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))\n",
    "    \n",
    "    return {\n",
    "        'normal': {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'F1': F1\n",
    "        },\n",
    "        'weighted': {\n",
    "            'precision': weightedPrecision,\n",
    "            'recall': weightedRecall,\n",
    "            'F1': weightedF1\n",
    "        }\n",
    "    }\n",
    "\n",
    "def K_global_score(groundTruth, prediction):\n",
    "    THRESHOLD = 0.5\n",
    "    videoLength = len(groundTruth)\n",
    "    \n",
    "    # normal score\n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0\n",
    "    totalPredictionSeconds = 0\n",
    "    \n",
    "    # weighted score\n",
    "    weightedOverlap = 0\n",
    "    totalWeightedClipSeconds = 0\n",
    "    totalWeightedPredictionSeconds = 0\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if groundTruth[i]:\n",
    "            totalClipSeconds += 1\n",
    "            totalWeightedClipSeconds += groundTruth[i]\n",
    "            \n",
    "            if prediction[i][0] > THRESHOLD:\n",
    "                totalPredictionSeconds += 1\n",
    "                totalWeightedPredictionSeconds += groundTruth[i]\n",
    "                \n",
    "                overlap += 1\n",
    "                weightedOverlap += groundTruth[i]\n",
    "        elif prediction[i][0] > THRESHOLD:\n",
    "            totalPredictionSeconds += 1\n",
    "            totalWeightedPredictionSeconds += 1 # no clip on this second, so weight is 1\n",
    "                \n",
    "    precision = overlap / totalPredictionSeconds if totalPredictionSeconds > 0 else 0\n",
    "    recall = overlap / totalClipSeconds if totalClipSeconds > 0 else 0\n",
    "    F1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    weightedPrecision = weightedOverlap / totalWeightedPredictionSeconds if totalWeightedPredictionSeconds > 0 else 0\n",
    "    weightedRecall = weightedOverlap / totalWeightedClipSeconds if totalWeightedClipSeconds > 0 else 0\n",
    "    weightedF1 = (2 * weightedPrecision * weightedRecall) / (weightedPrecision + weightedRecall) if (weightedPrecision + weightedRecall) > 0 else 0\n",
    "    \n",
    "    #print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "    #print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))\n",
    "    \n",
    "    return {\n",
    "        'normal': {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'F1': F1\n",
    "        },\n",
    "        'weighted': {\n",
    "            'precision': weightedPrecision,\n",
    "            'recall': weightedRecall,\n",
    "            'F1': weightedF1\n",
    "        }\n",
    "    }\n",
    "\n",
    "def evaluation(channel, video, predict): # WARNING!! it hasn't deal that answer is out of the video yet\n",
    "    global_answer = np.zeros(len(predict['macro']), dtype=int) # WARNING!! use dependent data len(predict['macro'])\n",
    "    \n",
    "    clipList = os.listdir(DATA_PATH + channel + '/'+ video +'/clip')\n",
    "    clipDataList = [] # ground true for loacl & macro\n",
    "    for clip in clipList:\n",
    "        with open(DATA_PATH + channel + '/'+ video +'/clip/' + clip, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "\n",
    "        data = json.loads(data)\n",
    "        \n",
    "        # generate ground true for local & macro evaluation metrics\n",
    "        clipDataList.append({\n",
    "            'offset': data['vod']['offset'],\n",
    "            'duration': math.ceil( data['duration'] ) # length of ground true clip\n",
    "        })\n",
    "        \n",
    "        # generate ground true for global evaluation metrics\n",
    "        for i in range(clipDataList[-1]['offset'], clipDataList[-1]['offset'] + clipDataList[-1]['duration']):\n",
    "            global_answer[i] += 1\n",
    "    \n",
    "    print(predict['count'])\n",
    "    local_score(clipDataList, predict['macro'], predict['count'])\n",
    "    #macro_score(clipDataList, predict['macro'])\n",
    "    global_score(global_answer, predict['global'])\n",
    "    \n",
    "def evaluationGlobalOnly(channel, video, prediction, clip_deadline = dt.datetime(9999,12,31,23,59,59), filter_low_views = False):\n",
    "    VIDEO_LENGTH = len(prediction) # WARNING!! use dependent data len(prediction)\n",
    "    VIEWS_THRESHOLD = 3\n",
    "    \n",
    "    global_answer = np.zeros(VIDEO_LENGTH, dtype=int)\n",
    "    \n",
    "    CLIP_PATH = DATA_PATH + channel + '/'+ video +'/clip/'\n",
    "    clipList = os.listdir(CLIP_PATH)\n",
    "    for clip in clipList:\n",
    "        with open(CLIP_PATH + clip, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "        clipInfo = json.loads(data)\n",
    "        \n",
    "        if filter_low_views and clipInfo['views'] < VIEWS_THRESHOLD:\n",
    "            continue # filter out a clip with low views\n",
    "        if stringToDateTime(clipInfo['created_at']) >= clip_deadline:\n",
    "            continue # filter out a clip created outside the range\n",
    "        \n",
    "        offset = clipInfo['vod']['offset']\n",
    "        duration = math.ceil( clipInfo['duration'] ) # length of ground true clip\n",
    "\n",
    "        if offset >= VIDEO_LENGTH: # check a clip is locate in the video range\n",
    "            continue\n",
    "\n",
    "        # generate ground true for global evaluation metrics\n",
    "        for i in range(offset, offset + duration):\n",
    "            if i >= VIDEO_LENGTH:\n",
    "                break\n",
    "            global_answer[i] += 1\n",
    "    \n",
    "    #print(channel + ' ' + video)\n",
    "    return K_global_score(global_answer, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 0\n",
    "recall = 0\n",
    "F1 = 0\n",
    "\n",
    "weightedPrecision = 0\n",
    "weightedRecall = 0\n",
    "weightedF1 = 0\n",
    "\n",
    "predictions = \n",
    "for mark, prediction in zip(TESTING_MARK, predictions):\n",
    "    with open(DATA_PATH + mark[0] + '/' + mark[1] + '/info.json', \"r\", encoding=\"utf-8\") as file: # mark[0]: channel, mark[1]: video\n",
    "        data = file.read()\n",
    "    videoInfo = json.loads(data)\n",
    "    \n",
    "    clipDeadline = stringToDateTime(videoInfo['created_at']) + dt.timedelta(seconds=videoInfo['length']) + dt.timedelta(days=CLIP_GRACE_PERIOD)\n",
    "    \n",
    "    scoreData = evaluationGlobalOnly(mark[0], mark[1], prediction[:videoInfo['length']], clipDeadline, True)\n",
    "    precision += scoreData['normal']['precision']\n",
    "    recall += scoreData['normal']['recall']\n",
    "    F1 += scoreData['normal']['F1']\n",
    "    weightedPrecision += scoreData['weighted']['precision']\n",
    "    weightedRecall += scoreData['weighted']['recall']\n",
    "    weightedF1 += scoreData['weighted']['F1']\n",
    "    \n",
    "\n",
    "precision /= len(predictions)\n",
    "recall /= len(predictions)\n",
    "F1 /= len(predictions)\n",
    "weightedPrecision /= len(predictions)\n",
    "weightedRecall /= len(predictions)\n",
    "weightedF1 /= len(predictions)\n",
    "print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
