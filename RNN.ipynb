{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:09:51.725564Z",
     "start_time": "2019-10-02T08:09:50.682441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, SimpleRNN, Masking, TimeDistributed, LSTM, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T12:34:11.290989Z",
     "start_time": "2019-10-15T12:33:49.751772Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Activation, SimpleRNN, Masking, TimeDistributed, LSTM, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from tensorflow.contrib.opt import AdamWOptimizer # remove from tf 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T10:41:11.242644Z",
     "start_time": "2019-09-13T10:41:11.239645Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "#tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T15:03:39.031288Z",
     "start_time": "2019-10-13T15:03:39.027289Z"
    }
   },
   "outputs": [],
   "source": [
    "DUMMY_VALUE = -1.0\n",
    "DATA_PATH = \"../TwitchHighlightCrawler/vod/\" # const\n",
    "\n",
    "TRAINING_TASK_ID = 'yb9ap3dscbr3p'\n",
    "SPECIFIC_TRAINING_DATA_ID = ''\n",
    "SPECIFIC_TRAINING_LABEL_ID = ''\n",
    "SPECIFIC_GROUND_TRUTH_ID = ''\n",
    "TESTING_TASK_ID = 'jf37cltm4hq68'\n",
    "SPECIFIC_TESTING_DATA_ID = ''\n",
    "SPECIFIC_TESTING_LABEL_ID = ''\n",
    "\n",
    "WINDOW = 1\n",
    "VIEWS_THRESHOLD = 3\n",
    "CLIP_GRACE_PERIOD = 14\n",
    "\n",
    "FEATURE_DATA_TYPE = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:23:16.198912Z",
     "start_time": "2019-10-02T08:23:15.729040Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.load('training_data-' + TRAINING_TASK_ID + (('-' + SPECIFIC_TRAINING_DATA_ID) if SPECIFIC_TRAINING_DATA_ID else '') + '.npy')\n",
    "Y = np.load('training_label-' + TRAINING_TASK_ID + (('-' + SPECIFIC_TRAINING_LABEL_ID) if SPECIFIC_TRAINING_LABEL_ID else '') + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T07:30:18.795405Z",
     "start_time": "2019-10-13T07:30:18.778424Z"
    },
    "code_folding": [
     0,
     4,
     22,
     37,
     51,
     64,
     69
    ]
   },
   "outputs": [],
   "source": [
    "def stringToDateTime(str): # only parse twitch info format\n",
    "    str = (str[:19] + 'Z') if len(str) > 20 else str\n",
    "    return dt.datetime.strptime(str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def computeClassWeight(y): # the return value of this function already assume negative data is large than positive data\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    \n",
    "    for sample in y:\n",
    "        for timestep in sample:\n",
    "            if timestep[0] > 0:\n",
    "                positive += 1\n",
    "            elif not timestep[0]:\n",
    "                negative += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return {\n",
    "        0: 1,\n",
    "        1: negative / positive\n",
    "    }\n",
    "\n",
    "def computeSampleWeight(y): # the return value of this function based on computeClassWeight()'s assumption \n",
    "    classWeight = computeClassWeight(y)\n",
    "    \n",
    "    sampleWeight = np.empty(y.shape[0:2])\n",
    "    for sampleIndex, sample in enumerate(y):\n",
    "        for timestepIndex, timestep in enumerate(sample):\n",
    "            if timestep[0] > 0:\n",
    "                sampleWeight[sampleIndex][timestepIndex] = classWeight[1]\n",
    "            elif not timestep[0]:\n",
    "                sampleWeight[sampleIndex][timestepIndex] = 1 # or classWeight[0]\n",
    "            else:\n",
    "                sampleWeight[sampleIndex][timestepIndex] = 0\n",
    "                \n",
    "    return sampleWeight\n",
    "\n",
    "def K_precision(y_true, y_pred): # this function assume DUMMY_VALUE is -1.0\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        masking_size = K.sum(K.round(K.clip(y_pred * y_true, DUMMY_VALUE, 0))) # this will be a negative value (or -0)\n",
    "        precision = true_positives / (predicted_positives + masking_size + K.epsilon()) # since masking will be a negative value, we plus it\n",
    "        return precision\n",
    "\n",
    "def K_recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def K_F1(y_true, y_pred):\n",
    "    precision = K_precision(y_true, y_pred)\n",
    "    recall = K_recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "dependencies = {\n",
    "    'K_precision': K_precision,\n",
    "    'K_recall': K_recall\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:23:55.554289Z",
     "start_time": "2019-10-02T08:23:18.641008Z"
    }
   },
   "outputs": [],
   "source": [
    "w = computeSampleWeight(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T15:01:07.949355Z",
     "start_time": "2019-10-13T15:01:07.941357Z"
    }
   },
   "outputs": [],
   "source": [
    "class dtatSequence(Sequence):\n",
    "    def __init__(self, data_path, id_list, batch_size, shuffle = True):\n",
    "        self.data_path = data_path\n",
    "        self.id_list = id_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.id_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.id_list) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_id = self.id_list[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        for data_id in batch_id:\n",
    "            x = np.load()\n",
    "        \n",
    "        \n",
    "        max_data_length = len(max(batch_x, key=len))\n",
    "        feature_dimension = len(batch_x[0][0])\n",
    "        \n",
    "        # pad each data to the same length\n",
    "        padding_x = np.full( (self.batch_size, max_data_length, feature_dimension), fill_value=DUMMY_VALUE, dtype=FEATURE_DATA_TYPE )\n",
    "        padding_y = np.full( (self.batch_size, max_data_length, 1), fill_value=DUMMY_VALUE, dtype=int )\n",
    "        for s, x in enumerate(batch_x):\n",
    "            video_length = len(x)\n",
    "            padding_x[s, 0:video_length, :] = x\n",
    "        del batch_x\n",
    "        for s, y in enumerate(batch_y):\n",
    "            video_length = len(y)\n",
    "            padding_y[s, 0:video_length, :] = y\n",
    "        del batch_y\n",
    "\n",
    "        return padding_x, padding_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-15T12:36:18.131529Z",
     "start_time": "2019-10-15T12:36:18.125526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6 7]\n",
      "[4 8 7]\n"
     ]
    }
   ],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self, dim):\n",
    "        self.kk = dim\n",
    "\n",
    "aa = np.array([5,6,7])\n",
    "a = DataGenerator(aa)\n",
    "aa[0] = 4\n",
    "print(a.kk) # [4 6 7]\n",
    "a.kk[1] = 8\n",
    "print(aa) # [4 8 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T18:34:13.362028Z",
     "start_time": "2019-10-14T18:34:13.357030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "b = DataGenerator(list(range(5)))\n",
    "print(b.kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:25:25.584062Z",
     "start_time": "2019-10-02T08:23:55.556276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 2)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 4)           80        \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 1)           5         \n",
      "=================================================================\n",
      "Total params: 85\n",
      "Trainable params: 85\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 317 samples, validate on 36 samples\n",
      "Epoch 1/30\n",
      "288/317 [==========================>...] - ETA: 3s - loss: 0.2956 - accuracy: 0.7848 - K_precision: 0.0884 - K_recall: 0.0659\n",
      "Epoch 00001: val_loss improved from inf to 0.36979, saving model to ./model_checkpoints/01-0.3698_test.h5\n",
      "317/317 [==============================] - 42s 132ms/sample - loss: 0.2921 - accuracy: 0.7838 - K_precision: 0.0899 - K_recall: 0.0662 - val_loss: 0.3698 - val_accuracy: 0.7653 - val_K_precision: 0.0846 - val_K_recall: 0.0326\n",
      "Epoch 2/30\n",
      "288/317 [==========================>...] - ETA: 3s - loss: 0.2898 - accuracy: 0.7354 - K_precision: 0.0969 - K_recall: 0.1169\n",
      "Epoch 00002: val_loss improved from 0.36979 to 0.36583, saving model to ./model_checkpoints/02-0.3658_test.h5\n",
      "317/317 [==============================] - 37s 117ms/sample - loss: 0.2909 - accuracy: 0.7333 - K_precision: 0.0960 - K_recall: 0.1182 - val_loss: 0.3658 - val_accuracy: 0.7132 - val_K_precision: 0.0930 - val_K_recall: 0.0728\n",
      "Epoch 3/30\n",
      " 32/317 [==>...........................] - ETA: 30s - loss: 0.3298 - accuracy: 0.7155 - K_precision: 0.1080 - K_recall: 0.1162"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2006be440107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mhistories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#32/317 [==>...........................] - ETA: 52:08 - loss: 0.2944 - acc: 0.8699 - K_precision: 0.1527 - K_recall: 4.0953e-04\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 393\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=DUMMY_VALUE, input_shape=(None, 300)))\n",
    "model.add(Bidirectional(LSTM(300, return_sequences=True, implementation=1)))\n",
    "#model.add(LSTM(2, return_sequences=True))\n",
    "#model.add(LSTM(1, return_sequences=True, activation='sigmoid'))\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', K_precision, K_recall],\n",
    "              sample_weight_mode='temporal')\n",
    "model.summary()\n",
    "\n",
    "modelName = 'SW-C2T2_WE_0401-0501_BILSTM300-tanh-i1-DENSE1-sigmoid_30-2'\n",
    "checkpoint = ModelCheckpoint(filepath='./model_checkpoints/{epoch:02d}-{val_loss:.4f}_' + modelName + '.h5', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=10, verbose=1)\n",
    "histories = []\n",
    "histories.append( model.fit(X, Y, epochs=30, batch_size=2, validation_split=0.1, callbacks=[es, checkpoint], sample_weight=w) ) #\n",
    "model.save(modelName + '.h5')\n",
    "#32/317 [==>...........................] - ETA: 52:08 - loss: 0.2944 - acc: 0.8699 - K_precision: 0.1527 - K_recall: 4.0953e-04\n",
    "#32/317 [==>...........................] - ETA: 52:03 - loss: 5.4406 - acc: 0.8645 - K_precision: 0.0828 - K_recall: 0.0021\n",
    "\n",
    "#1/317 [..............................] - ETA: 28:10:04 - loss: 0.4223 - acc: 0.1861 - K_precision: 0.1867 - K_recall: 0.9714\n",
    "#1/317 [..............................] - ETA: 24:35:47 - loss: 4.9976 - acc: 0.7712 - K_precision: 0.0000e+00 - K_recall: 0.0000e+00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T11:42:48.758095Z",
     "start_time": "2019-08-02T11:42:48.498179Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 1000 arrays: [array([[0.51024308],\n       [0.3404787 ],\n       [0.07502523],\n       [0.26591401],\n       [0.2502586 ],\n       [0.28769308],\n       [0.43627578],\n       [0.19952613],\n       [0.87965262],\n       [0....",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cae4737ed1de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 训练模型，以 32 个样本为一个 batch 进行迭代\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 1000 arrays: [array([[0.51024308],\n       [0.3404787 ],\n       [0.07502523],\n       [0.26591401],\n       [0.2502586 ],\n       [0.28769308],\n       [0.43627578],\n       [0.19952613],\n       [0.87965262],\n       [0...."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "'''data = np.random.random((1000, 10))\n",
    "labels = np.random.randint(2, size=(1000, 1))'''\n",
    "data = []\n",
    "labels = []\n",
    "import random\n",
    "for i in range(1000):\n",
    "    data.append(np.random.random(10))\n",
    "    labels.append(random.randint(0,1))\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-03T09:58:48.801962Z",
     "start_time": "2019-08-03T09:58:48.792962Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.95156836, 0.5257626 ],\n",
       "        [0.00156089, 0.85387701],\n",
       "        [0.78281018, 0.73223741],\n",
       "        [0.37595671, 0.49269121],\n",
       "        [0.92361927, 0.67693445],\n",
       "        [0.9214292 , 0.72112536],\n",
       "        [0.66214929, 0.10112643],\n",
       "        [0.90462236, 0.31870872],\n",
       "        [0.15810725, 0.73876466],\n",
       "        [0.53127291, 0.89857455]],\n",
       "\n",
       "       [[0.95156836, 0.5257626 ],\n",
       "        [0.00156089, 0.85387701],\n",
       "        [0.78281018, 0.73223741],\n",
       "        [0.37595671, 0.49269121],\n",
       "        [0.92361927, 0.67693445],\n",
       "        [0.9214292 , 0.72112536],\n",
       "        [0.66214929, 0.10112643],\n",
       "        [0.90462236, 0.31870872],\n",
       "        [0.15810725, 0.73876466],\n",
       "        [0.53127291, 0.89857455]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data = np.array([])\n",
    "data = np.append(data, np.random.random((10, 2)), axis=0)\n",
    "#data = np.append(data, np.random.random((10, 2)), axis=0)\n",
    "#np.concatenate((data, np.random.random((1,10, 2))),axis=0 )\n",
    "np.random.random((10, 2))\n",
    "data'''\n",
    "import random\n",
    "d = []\n",
    "features = []\n",
    "for i in range(10):\n",
    "    feature = []\n",
    "    for j in range(2):\n",
    "        feature.append(random.random())\n",
    "    features.append(feature)\n",
    "    \n",
    "d.append(features)\n",
    "d.append(features)\n",
    "np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T11:52:06.094524Z",
     "start_time": "2019-08-21T11:51:54.240525Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0821 19:51:54.256520  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0821 19:51:54.494101  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0821 19:51:54.571093  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0821 19:51:54.920798  4772 deprecation.py:323] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0821 19:51:55.028765  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0821 19:51:55.047758  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0821 19:51:55.607579  4772 deprecation_wrapper.py:119] From D:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 10s 989ms/step - loss: 0.7155 - acc: 0.5360\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6940 - acc: 0.5642\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6936 - acc: 0.5517\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6891 - acc: 0.5585\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6891 - acc: 0.5601\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6850 - acc: 0.5660\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6834 - acc: 0.5632\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6814 - acc: 0.5998\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6785 - acc: 0.5844\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6771 - acc: 0.5918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a38b91470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成虚拟数据\n",
    "import random\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "max_seq_len = 0\n",
    "\n",
    "N = 10 # number of data\n",
    "\n",
    "dummy = -1\n",
    "for i in range(N):\n",
    "    length = random.randint(5,25)\n",
    "    if length > max_seq_len:\n",
    "        max_seq_len = length\n",
    "    #length = 10\n",
    "    data.append( np.random.random((length, 2))  )\n",
    "    labels.append( np.random.randint(2, size=(length, 1)) )\n",
    "#np.set_printoptions(threshold=False)\n",
    "\n",
    "Xpad = np.full((N, max_seq_len, 2), fill_value=dummy, dtype='float64')\n",
    "Ypad = np.full((N, max_seq_len, 1), fill_value=dummy, dtype='float64')\n",
    "for s, x in enumerate(data):\n",
    "    video_length = len(x)\n",
    "    Xpad[s, 0:video_length, :] = x\n",
    "for s, y in enumerate(labels):\n",
    "    video_length = len(y)\n",
    "    Ypad[s, 0:video_length, :] = y\n",
    "\n",
    "#data = np.array(data)\n",
    "#labels = np.array(labels)\n",
    "#print(data.shape)\n",
    "#print(labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "#input = Input(shape=(None, 2))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=dummy, input_shape=(None, 2)))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(1, return_sequences=True, activation='sigmoid'))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "#model.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "'''data = []\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(Xpad)\n",
    "    print(data)'''\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "#model.fit(data, labels, epochs=10, batch_size=8)\n",
    "model.fit(Xpad, Ypad, epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T11:55:33.888120Z",
     "start_time": "2019-08-21T11:55:33.821142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[2, 5],\n",
      "        [3, 6],\n",
      "        [4, 8]]]), array([[[2, 5],\n",
      "        [3, 6]]])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3,2) into shape (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-72f7ff146840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3,2) into shape (1)"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "\n",
    "'''import random\n",
    "features = []\n",
    "for i in range(10):\n",
    "    feature = []\n",
    "    for j in range(2):\n",
    "        feature.append(random.random())\n",
    "    features.append(feature)\n",
    "test.append(features)\n",
    "test1 = np.array(test)\n",
    "\n",
    "test = []\n",
    "features = []\n",
    "for i in range(6):\n",
    "    feature = []\n",
    "    for j in range(2):\n",
    "        feature.append(random.random())\n",
    "    features.append(feature)\n",
    "test.append(features)\n",
    "test2 = np.array(test)\n",
    "\n",
    "test = np.array(test)\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    for i in range(2):\n",
    "        print(model.predict(test, batch_size=8))'''\n",
    "\n",
    "'''test = np.array([ [[[2,5],[3,6],[4,8]]], [[[2,5],[3,6]]] ]) # 4維 沒用\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(model.predict(test[0], batch_size=8))'''\n",
    "\n",
    "'''a = np.array([[[2,5],[3,6],[4,8]]])\n",
    "b = np.array([[[2,5],[3,6]]])\n",
    "c = []\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "test = np.array(c) # 無解 這行出錯\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(model.predict(test[0], batch_size=8))'''\n",
    "\n",
    "'''test.append(np.random.random((10, 2)))\n",
    "test.append(np.random.random((6, 2)))\n",
    "#test = np.array(test)\n",
    "Tpad = np.full((2, 10, 2), fill_value=dummy, dtype='Float64')\n",
    "for s, t in enumerate(test):\n",
    "    video_length = len(t)\n",
    "    Tpad[s, 0:video_length, :] = t\n",
    "\n",
    "with np.printoptions(threshold=np.inf):\n",
    "    print(model.predict(Tpad, batch_size=8))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:18:18.606314Z",
     "start_time": "2019-09-28T07:18:18.602314Z"
    }
   },
   "outputs": [],
   "source": [
    "adamw = AdamWOptimizer(weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T09:27:34.671832Z",
     "start_time": "2019-09-28T09:27:31.123277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 267ms/sample - loss: 1.3977 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 1.3896 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 1.3808 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 1.3715 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 1.3621 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 1.3525 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 1.3429 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 1.3333 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 1.3237 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 1.3143 - acc: 0.2000 - K_F1: 0.3333 - K_precision: 0.2000 - K_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1],\n",
       "        [1],\n",
       "        [1]],\n",
       "\n",
       "       [[1],\n",
       "        [1],\n",
       "        [1]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=DUMMY_VALUE, input_shape=(None, 2)))\n",
    "model.add(SimpleRNN(1, return_sequences=True, activation='sigmoid'))\n",
    "model.compile(optimizer=adamw,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', K_F1, K_precision, K_recall],\n",
    "             sample_weight_mode='temporal')\n",
    "\n",
    "X = np.array([[[1, 2], [2, 3], [3, 4]], [[4, 5], [6, 9], [-1, -1]]])\n",
    "Y = np.array([[[0], [1], [0]], [[0], [0], [-1]]])\n",
    "#w = np.array([[1,1,1], [1,1,0]])\n",
    "w = computeSampleWeight(Y)\n",
    "\n",
    "model.fit(X, Y, epochs=10, batch_size=8, sample_weight=w)\n",
    "#model.predict(X)\n",
    "prediction = model.predict_classes(X)\n",
    "prediction\n",
    "#type(prediction[0][0][0]) # numpy.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-13T12:01:50.568426Z",
     "start_time": "2019-09-13T12:01:50.562429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., -0., -1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0.48, 0.5, 0.51])\n",
    "b = np.array([0, -1, -1])\n",
    "np.round(np.clip(a*b, -1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T13:44:36.428897Z",
     "start_time": "2019-10-13T13:44:36.420911Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "max_seq_len = 0\n",
    "\n",
    "N = 10 # number of data\n",
    "\n",
    "dummy = -1\n",
    "for i in range(N):\n",
    "    length = random.randint(5,25)\n",
    "    if length > max_seq_len:\n",
    "        max_seq_len = length\n",
    "    #length = 10\n",
    "    data.append( np.random.random((length, 2))  )\n",
    "    labels.append( np.random.randint(2, size=(length, 1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T16:41:28.357830Z",
     "start_time": "2019-10-13T16:41:25.668561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 514ms/step - loss: 0.3068 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3066 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.3062 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3060 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3057 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3054 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3050 - accuracy: 0.5280 - K_F1: 0.6536 - K_precision: 0.5082 - K_recall: 0.9162\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3049 - accuracy: 0.5200 - K_F1: 0.6455 - K_precision: 0.5035 - K_recall: 0.8994\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3045 - accuracy: 0.5200 - K_F1: 0.6455 - K_precision: 0.5035 - K_recall: 0.8994\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3042 - accuracy: 0.5200 - K_F1: 0.6455 - K_precision: 0.5035 - K_recall: 0.8994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=DUMMY_VALUE, input_shape=(None, 2)))\n",
    "model.add(SimpleRNN(1, return_sequences=True, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', K_F1, K_precision, K_recall],\n",
    "             sample_weight_mode='temporal')\n",
    "\n",
    "X = np.array(data)\n",
    "Y = np.array(labels)\n",
    "\n",
    "model.fit_generator(dtatSequence(X, Y, 8), epochs=10)\n",
    "X = np.array([[[1, 2], [2, 3], [3, 4]], [[4, 5], [6, 9], [-1, -1]]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T07:29:57.137133Z",
     "start_time": "2019-10-13T07:29:57.074151Z"
    },
    "code_folding": [
     0,
     84,
     176,
     206,
     258,
     312,
     338,
     346,
     350,
     352,
     358,
     363
    ]
   },
   "outputs": [],
   "source": [
    "def local_score(clipDataList, predict, numberOfPredictedFragment):\n",
    "    localPrecision = 0\n",
    "    localRecall = 0\n",
    "    \n",
    "    videoLength = len(predict)\n",
    "    \n",
    "    for clip in clipDataList:\n",
    "        recall = 0\n",
    "        overlapTime = 0 # for local recall computing\n",
    "\n",
    "        endOfClip = clip['offset'] + clip['duration'] # not real video end timeline point\n",
    "\n",
    "        for i in range(clip['offset'] - (MAX_CLIP_LENGTH-1), clip['offset'] - MIN_CLIP_LENGTH + 1): # (offset - 59) <= prediction <= (offset - 5) # eg. offset = 85, duration = 10, 26~80\n",
    "            if predict[i] and (i + predict[i]['duration']) > clip['offset']: # Simplify from (i + (predict[i]['duration']-1)) >= clip['offset']\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset'] # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip:\n",
    "                    overlap -= (endOfPrediction - endOfClip) # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'] - MIN_CLIP_LENGTH + 1, clip['offset']): # (offset - 4(less than MIN_CLIP_LENGTH)) <= prediction < offset # 81~84\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset']; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip: # predicted fragment is larger than clip\n",
    "                    overlap -= (endOfPrediction - endOfClip); # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'], endOfClip): # offset <= prediction < (offset + duration) # 85~94\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfClip - i; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction < endOfClip: # predicted fragment is smaller than clip\n",
    "                    overlap -= endOfClip - endOfPrediction\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        if overlapTime:\n",
    "            recall /= overlapTime\n",
    "            localRecall += recall\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if predict[i]: # check have predicted fragment\n",
    "            if len(predict[i]['precision']): # the fragment has overlap\n",
    "                precision = 0 # for local precision computing\n",
    "\n",
    "                for singlePrecisionValue in predict[i]['precision']:\n",
    "                    # local precision\n",
    "                    precision += singlePrecisionValue\n",
    "                precision /= len(predict[i]['precision'])\n",
    "\n",
    "                localPrecision += precision\n",
    "\n",
    "    localPrecision /= numberOfPredictedFragment\n",
    "    localRecall /= len(clipDataList)\n",
    "    F1 = (2 * localPrecision * localRecall) / (localPrecision + localRecall)\n",
    "    print(str(localPrecision) + ' ' + str(localRecall) + ' ' + str(F1))\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "    \n",
    "def macro_score(clipDataList, predict):\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    macroF1 = 0\n",
    "    \n",
    "    videoLength = len(predict)\n",
    "    \n",
    "    for clip in clipDataList:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        F1 = 0\n",
    "        \n",
    "        overlapTime = 0\n",
    "\n",
    "        endOfClip = clip['offset'] + clip['duration'] # not real video end timeline point\n",
    "\n",
    "        for i in range(clip['offset'] - (MAX_CLIP_LENGTH-1), clip['offset'] - MIN_CLIP_LENGTH + 1): # (offset - 59) <= prediction <= (offset - 5) # eg. offset = 85, duration = 10, 26~80\n",
    "            if predict[i] and (i + predict[i]['duration']) > clip['offset']: # Simplify from (i + (predict[i]['duration']-1)) >= clip['offset']\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset'] # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip:\n",
    "                    overlap -= (endOfPrediction - endOfClip) # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'] - MIN_CLIP_LENGTH + 1, clip['offset']): # (offset - 4(less than MIN_CLIP_LENGTH)) <= prediction < offset # 81~84\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset']; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip: # predicted fragment is larger than clip\n",
    "                    overlap -= (endOfPrediction - endOfClip); # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'], endOfClip): # offset <= prediction < (offset + duration) # 85~94\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfClip - i; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction < endOfClip: # predicted fragment is smaller than clip\n",
    "                    overlap -= endOfClip - endOfPrediction\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        if overlapTime:\n",
    "            precision /= overlapTime\n",
    "            recall /= overlapTime\n",
    "            F1 /= overlapTime\n",
    "            \n",
    "            macroPrecision += precision\n",
    "            macroRecall += recall\n",
    "            macroF1 += F1\n",
    "    \n",
    "    numberOfAnswer = len(clipDataList)\n",
    "    \n",
    "    macroPrecision /= numberOfAnswer\n",
    "    macroRecall /= numberOfAnswer\n",
    "    macroF1 /= numberOfAnswer  \n",
    "    print(str(macroPrecision) + ' ' + str(macroRecall) + ' ' + str(macroF1))\n",
    "    \n",
    "def K_simple_global_score(label, prediction): # use to evaluation training data\n",
    "    THRESHOLD = 0.5\n",
    "    \n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0\n",
    "    totalPredictionSeconds = 0\n",
    "    \n",
    "    length = len(label)\n",
    "    for i in range(length):\n",
    "        if label[i][0] == -1:\n",
    "            break\n",
    "            \n",
    "        if prediction[i][0] > THRESHOLD:\n",
    "            totalPredictionSeconds += 1\n",
    "            if label[i][0]:\n",
    "                totalClipSeconds += 1\n",
    "                overlap += 1\n",
    "        elif label[i][0]:\n",
    "            totalClipSeconds += 1\n",
    "            \n",
    "    precision = (overlap / totalPredictionSeconds) if totalPredictionSeconds > 0 else 0\n",
    "    recall = (overlap / totalClipSeconds) if totalClipSeconds > 0 else 0\n",
    "    F1 = ((2 * precision * recall) / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "            \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "\n",
    "def global_score(groundTruth, predict):\n",
    "    videoLength = len(groundTruth)\n",
    "    \n",
    "    # normal score\n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0 # WARNING!! we can count this value when computing local score\n",
    "    totalPredictionSeconds = 0\n",
    "    \n",
    "    # weighted score\n",
    "    weightedOverlap = 0\n",
    "    totalWeightedClipSeconds = 0 # WARNING!! we can count this value when computing local score\n",
    "    totalWeightedPredictionSeconds = 0\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if groundTruth[i]:\n",
    "            totalClipSeconds += 1\n",
    "            totalWeightedClipSeconds += groundTruth[i]\n",
    "            \n",
    "            if predict[i]:\n",
    "                totalPredictionSeconds += 1\n",
    "                totalWeightedPredictionSeconds += groundTruth[i]\n",
    "                \n",
    "                overlap += 1\n",
    "                weightedOverlap += groundTruth[i]\n",
    "        elif predict[i]:\n",
    "            totalPredictionSeconds += 1\n",
    "            totalWeightedPredictionSeconds += 1 # no clip on this second, so weight is 1\n",
    "                \n",
    "    precision = overlap / totalPredictionSeconds if totalPredictionSeconds > 0 else 0\n",
    "    recall = overlap / totalClipSeconds if totalClipSeconds > 0 else 0\n",
    "    F1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    weightedPrecision = weightedOverlap / totalWeightedPredictionSeconds if totalWeightedPredictionSeconds > 0 else 0\n",
    "    weightedRecall = weightedOverlap / totalWeightedClipSeconds if totalWeightedClipSeconds > 0 else 0\n",
    "    weightedF1 = (2 * weightedPrecision * weightedRecall) / (weightedPrecision + weightedRecall) if (weightedPrecision + weightedRecall) > 0 else 0\n",
    "    \n",
    "    #print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "    #print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))\n",
    "    \n",
    "    return {\n",
    "        'normal': {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'F1': F1\n",
    "        },\n",
    "        'weighted': {\n",
    "            'precision': weightedPrecision,\n",
    "            'recall': weightedRecall,\n",
    "            'F1': weightedF1\n",
    "        }\n",
    "    }\n",
    "\n",
    "def K_global_score(groundTruth, prediction):\n",
    "    THRESHOLD = 0.5\n",
    "    videoLength = len(groundTruth)\n",
    "    \n",
    "    # normal score\n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0\n",
    "    totalPredictionSeconds = 0\n",
    "    \n",
    "    # weighted score\n",
    "    weightedOverlap = 0\n",
    "    totalWeightedClipSeconds = 0\n",
    "    totalWeightedPredictionSeconds = 0\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if groundTruth[i]:\n",
    "            totalClipSeconds += 1\n",
    "            totalWeightedClipSeconds += groundTruth[i]\n",
    "            \n",
    "            if prediction[i][0] > THRESHOLD:\n",
    "                totalPredictionSeconds += 1\n",
    "                totalWeightedPredictionSeconds += groundTruth[i]\n",
    "                \n",
    "                overlap += 1\n",
    "                weightedOverlap += groundTruth[i]\n",
    "        elif prediction[i][0] > THRESHOLD:\n",
    "            totalPredictionSeconds += 1\n",
    "            totalWeightedPredictionSeconds += 1 # no clip on this second, so weight is 1\n",
    "                \n",
    "    precision = overlap / totalPredictionSeconds if totalPredictionSeconds > 0 else 0\n",
    "    recall = overlap / totalClipSeconds if totalClipSeconds > 0 else 0\n",
    "    F1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    weightedPrecision = weightedOverlap / totalWeightedPredictionSeconds if totalWeightedPredictionSeconds > 0 else 0\n",
    "    weightedRecall = weightedOverlap / totalWeightedClipSeconds if totalWeightedClipSeconds > 0 else 0\n",
    "    weightedF1 = (2 * weightedPrecision * weightedRecall) / (weightedPrecision + weightedRecall) if (weightedPrecision + weightedRecall) > 0 else 0\n",
    "    \n",
    "    #print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "    #print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))\n",
    "    print(str(precision) + ' ' + str(recall) + ' ' + str(F1) + ' ' + str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))\n",
    "    \n",
    "    return {\n",
    "        'normal': {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'F1': F1\n",
    "        },\n",
    "        'weighted': {\n",
    "            'precision': weightedPrecision,\n",
    "            'recall': weightedRecall,\n",
    "            'F1': weightedF1\n",
    "        }\n",
    "    }\n",
    "\n",
    "def evaluation(channel, video, predict): # WARNING!! it hasn't deal that answer is out of the video yet\n",
    "    global_answer = np.zeros(len(predict['macro']), dtype=int) # WARNING!! use dependent data len(predict['macro'])\n",
    "    \n",
    "    clipList = os.listdir(DATA_PATH + channel + '/'+ video +'/clip')\n",
    "    clipDataList = [] # ground true for loacl & macro\n",
    "    for clip in clipList:\n",
    "        with open(DATA_PATH + channel + '/'+ video +'/clip/' + clip, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "\n",
    "        data = json.loads(data)\n",
    "        \n",
    "        # generate ground true for local & macro evaluation metrics\n",
    "        clipDataList.append({\n",
    "            'offset': data['vod']['offset'],\n",
    "            'duration': math.ceil( data['duration'] ) # length of ground true clip\n",
    "        })\n",
    "        \n",
    "        # generate ground true for global evaluation metrics\n",
    "        for i in range(clipDataList[-1]['offset'], clipDataList[-1]['offset'] + clipDataList[-1]['duration']):\n",
    "            global_answer[i] += 1\n",
    "    \n",
    "    print(predict['count'])\n",
    "    local_score(clipDataList, predict['macro'], predict['count'])\n",
    "    #macro_score(clipDataList, predict['macro'])\n",
    "    global_score(global_answer, predict['global'])\n",
    "    \n",
    "def K_evaluationGlobalOnly(channel, video, prediction, clip_deadline = dt.datetime(9999,12,31,23,59,59), filter_low_views = False):\n",
    "    VIDEO_LENGTH = len(prediction) # WARNING!! use dependent data len(prediction)\n",
    "    \n",
    "    global_answer = np.zeros(VIDEO_LENGTH, dtype=int)\n",
    "    \n",
    "    CLIP_PATH = DATA_PATH + channel + '/'+ video +'/clip/'\n",
    "    clipList = os.listdir(CLIP_PATH)\n",
    "    for clip in clipList:\n",
    "        with open(CLIP_PATH + clip, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "        clipInfo = json.loads(data)\n",
    "        \n",
    "        if filter_low_views and clipInfo['views'] < VIEWS_THRESHOLD:\n",
    "            continue # filter out a clip with low views\n",
    "        if stringToDateTime(clipInfo['created_at']) >= clip_deadline:\n",
    "            continue # filter out a clip created outside the range\n",
    "        \n",
    "        offset = clipInfo['vod']['offset']\n",
    "        duration = math.ceil( clipInfo['duration'] ) # length of ground true clip\n",
    "\n",
    "        if offset >= VIDEO_LENGTH: # check a clip is locate in the video range\n",
    "            continue\n",
    "\n",
    "        # generate ground true for global evaluation metrics\n",
    "        for i in range(offset, offset + duration):\n",
    "            if i >= VIDEO_LENGTH:\n",
    "                break\n",
    "            global_answer[i] += 1\n",
    "    \n",
    "    #print(channel + ' ' + video)\n",
    "    return K_global_score(global_answer, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12,
     24
    ]
   },
   "outputs": [],
   "source": [
    "TRAINING_MARK = np.load('training_mark-' + TRAINING_TASK_ID + '.npy')\n",
    "\n",
    "# evaluate training set\n",
    "precision = 0\n",
    "recall = 0\n",
    "F1 = 0\n",
    "\n",
    "weightedPrecision = 0\n",
    "weightedRecall = 0\n",
    "weightedF1 = 0\n",
    "\n",
    "for mark, prediction in zip(TRAINING_MARK, predictions):\n",
    "    with open(DATA_PATH + mark[0] + '/' + mark[1] + '/info.json', \"r\", encoding=\"utf-8\") as file: # mark[0]: channel, mark[1]: video\n",
    "        data = file.read()\n",
    "    videoInfo = json.loads(data)\n",
    "        \n",
    "    if WINDOW > 1:\n",
    "        realPrediction = np.empty( (videoInfo['length'], 1), dtype=int )\n",
    "        \n",
    "        predictionLength = len(prediction)\n",
    "        for t in range(predictionLength):\n",
    "            realVideoIndex = t * WINDOW\n",
    "            upperBound = realVideoIndex + WINDOW # end of this window \n",
    "            \n",
    "            if upperBound > videoInfo['length']: # check if is out of the range\n",
    "                upperBound = videoInfo['length']\n",
    "            realPrediction[realVideoIndex:upperBound] = prediction[t]\n",
    "    else:\n",
    "        realPrediction = prediction[:videoInfo['length']]\n",
    "        \n",
    "    clipDeadline = stringToDateTime(videoInfo['created_at']) + dt.timedelta(seconds=videoInfo['length']) + dt.timedelta(days=CLIP_GRACE_PERIOD)\n",
    "\n",
    "    scoreData = K_evaluationGlobalOnly(mark[0], mark[1], realPrediction, clipDeadline, True)\n",
    "    precision += scoreData['normal']['precision']\n",
    "    recall += scoreData['normal']['recall']\n",
    "    F1 += scoreData['normal']['F1']\n",
    "    weightedPrecision += scoreData['weighted']['precision']\n",
    "    weightedRecall += scoreData['weighted']['recall']\n",
    "    weightedF1 += scoreData['weighted']['F1']\n",
    "    \n",
    "precision /= len(predictions)\n",
    "recall /= len(predictions)\n",
    "F1 /= len(predictions)\n",
    "weightedPrecision /= len(predictions)\n",
    "weightedRecall /= len(predictions)\n",
    "weightedF1 /= len(predictions)\n",
    "print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     22
    ]
   },
   "outputs": [],
   "source": [
    "GROUND_TRUTH = np.load('ground_truth-' + TRAINING_TASK_ID + (('-' + SPECIFIC_GROUND_TRUTH_ID) if SPECIFIC_GROUND_TRUTH_ID else '') +'.npy', allow_pickle=True)\n",
    "\n",
    "# evaluate training set (if has ground truth data)\n",
    "precision = 0\n",
    "recall = 0\n",
    "F1 = 0\n",
    "\n",
    "weightedPrecision = 0\n",
    "weightedRecall = 0\n",
    "weightedF1 = 0\n",
    "\n",
    "for prediction, label in zip(predictions, GROUND_TRUTH):\n",
    "    videoLength = len(label) # there is no padding in label data\n",
    "    \n",
    "    if WINDOW > 1:\n",
    "        realPrediction = np.empty( (videoLength, 1), dtype=int )\n",
    "        \n",
    "        predictionLength = len(prediction)\n",
    "        for t in range(predictionLength):\n",
    "            realVideoIndex = t * WINDOW\n",
    "            upperBound = realVideoIndex + WINDOW # end of this window \n",
    "            \n",
    "            if upperBound > videoLength: # check if is out of the range\n",
    "                upperBound = videoLength\n",
    "            realPrediction[realVideoIndex:upperBound] = prediction[t]\n",
    "    else:\n",
    "        realPrediction = prediction[:videoLength]\n",
    "    \n",
    "    scoreData = K_global_score(label, realPrediction)\n",
    "    precision += scoreData['normal']['precision']\n",
    "    recall += scoreData['normal']['recall']\n",
    "    F1 += scoreData['normal']['F1']\n",
    "    weightedPrecision += scoreData['weighted']['precision']\n",
    "    weightedRecall += scoreData['weighted']['recall']\n",
    "    weightedF1 += scoreData['weighted']['F1']\n",
    "    \n",
    "precision /= len(predictions)\n",
    "recall /= len(predictions)\n",
    "F1 /= len(predictions)\n",
    "weightedPrecision /= len(predictions)\n",
    "weightedRecall /= len(predictions)\n",
    "weightedF1 /= len(predictions)\n",
    "print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     20
    ]
   },
   "outputs": [],
   "source": [
    "# evaluate testing set\n",
    "precision = 0\n",
    "recall = 0\n",
    "F1 = 0\n",
    "\n",
    "weightedPrecision = 0\n",
    "weightedRecall = 0\n",
    "weightedF1 = 0\n",
    "\n",
    "for prediction, label in zip(predictions, TESTING_LABEL):\n",
    "    videoLength = len(label) # there is no padding in label data\n",
    "    \n",
    "    if WINDOW > 1:\n",
    "        realPrediction = np.empty( (videoLength, 1), dtype=int )\n",
    "        \n",
    "        predictionLength = len(prediction)\n",
    "        for t in range(predictionLength):\n",
    "            realVideoIndex = t * WINDOW\n",
    "            upperBound = realVideoIndex + WINDOW # end of this window \n",
    "            \n",
    "            if upperBound > videoLength: # check if is out of the range\n",
    "                upperBound = videoLength\n",
    "            realPrediction[realVideoIndex:upperBound] = prediction[t]\n",
    "    else:\n",
    "        realPrediction = prediction[:videoLength]\n",
    "    \n",
    "    scoreData = K_global_score(label, realPrediction)\n",
    "    precision += scoreData['normal']['precision']\n",
    "    recall += scoreData['normal']['recall']\n",
    "    F1 += scoreData['normal']['F1']\n",
    "    weightedPrecision += scoreData['weighted']['precision']\n",
    "    weightedRecall += scoreData['weighted']['recall']\n",
    "    weightedF1 += scoreData['weighted']['F1']\n",
    "    \n",
    "precision /= len(predictions)\n",
    "recall /= len(predictions)\n",
    "F1 /= len(predictions)\n",
    "weightedPrecision /= len(predictions)\n",
    "weightedRecall /= len(predictions)\n",
    "weightedF1 /= len(predictions)\n",
    "print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     25,
     33
    ]
   },
   "outputs": [],
   "source": [
    "def evaluateBaseline(mark, window=1):\n",
    "    CLIP_GRACE_PERIOD = 14\n",
    "    \n",
    "    # score about frequency method\n",
    "    precisionForFrequencyMethod = 0\n",
    "    recallForFrequencyMethod = 0\n",
    "    F1ForFrequencyMethod = 0\n",
    "\n",
    "    weightedPrecisionForFrequencyMethod = 0\n",
    "    weightedRecallForFrequencyMethod = 0\n",
    "    weightedF1ForFrequencyMethod = 0\n",
    "    \n",
    "    # score about diversity method\n",
    "    precisionForDiversityMethod = 0\n",
    "    recallForDiversityMethod = 0\n",
    "    F1ForDiversityMethod = 0\n",
    "\n",
    "    weightedPrecisionForDiversityMethod = 0\n",
    "    weightedRecallForDiversityMethod = 0\n",
    "    weightedF1ForDiversityMethod = 0\n",
    "    \n",
    "    for videInfo in mark:\n",
    "        VIDEO_PATH = DATA_PATH + mark[0] + '/'+ mark[1] +'/' # local const\n",
    "        \n",
    "        # read video info\n",
    "        with open(VIDEO_PATH + 'info.json', \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "        videoInfo = json.loads(data)\n",
    "        \n",
    "        # process message data (it can be optimized)\n",
    "        messages = [[] for i in range(videoInfo['length'])]\n",
    "\n",
    "        messagePathList = glob.glob(VIDEO_PATH + 'Message-*.json')\n",
    "        for path in messagePathList:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "\n",
    "            commentData = json.loads(data)['comments']\n",
    "            for comment in commentData:\n",
    "                offset = math.floor( comment['content_offset_seconds'] ) # get comment offset\n",
    "\n",
    "                if offset >= videoInfo['length']:\n",
    "                    break\n",
    "                if only_chat and comment['source'] != 'chat':\n",
    "                    if comment['source'] != 'comment':\n",
    "                        print(channel + ' ' + video + ' ' + str(offset) + ' ' + comment['source'])\n",
    "                    continue\n",
    "                if comment['state'] != 'published':\n",
    "                    print(channel + ' ' + video + ' ' + str(offset) + ' ' + comment['state'])\n",
    "\n",
    "                messages[offset].append( comment['message']['body'] )\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T07:26:29.171341Z",
     "start_time": "2019-09-28T07:26:29.164344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [5.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.zeros((5,1))\n",
    "b=np.array([[1],[0],[5],[1],[0]])\n",
    "a[2:3] = b[2]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-28T09:29:35.777130Z",
     "start_time": "2019-09-28T09:29:35.773135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n"
     ]
    }
   ],
   "source": [
    "if(b[-1]):\n",
    "    print(87)\n",
    "else:\n",
    "    print(899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T09:02:29.877919Z",
     "start_time": "2019-10-13T09:02:29.870921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [1,2], [1,2,3,4,5], [1,2,3,4]])\n",
    "len(max(a, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T09:28:36.459817Z",
     "start_time": "2019-10-13T09:28:36.453806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7, -1, -1, -1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7]\n",
    "b = np.full( 10, fill_value=DUMMY_VALUE, dtype=int )\n",
    "b[:len(a)] = a\n",
    "del a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
