{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:11:26.515159Z",
     "start_time": "2019-07-08T16:11:25.261115Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T17:06:50.897658Z",
     "start_time": "2019-07-08T17:06:50.892669Z"
    }
   },
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "DATA_PATH = \"../TwitchHighlightCrawler/vod/\" # const\n",
    "\n",
    "MAX_CLIP_LENGTH = 60 # const\n",
    "MIN_CLIP_LENGTH = 5 # const\n",
    "\n",
    "DIVERSITY_BASE_WINDOW = 30 # const for diversity method\n",
    "DIVERSITY_THRESHOLD = 0.835 # const for diversity method\n",
    "\n",
    "_test = [{'channel': 'ninja', 'video':'425622866'}, {'channel': 'shroud', 'video':'259514478'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "videoLength = 28662 # temp const\n",
    "numberOfMessage = 1276 # temp const\n",
    "with open(\"../TwitchHighlightCrawler/comments.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    commentFQ = file.read()\n",
    "commentFQ = json.loads(commentFQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"c.txt\", \"r\") as clip_file:\n",
    "    globalClip = clip_file.read()\n",
    "    \n",
    "globalClip = json.loads(globalClip)['data'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:11:26.529647Z",
     "start_time": "2019-07-08T16:11:26.521650Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def normalized_shannon_entropy(text): # entropy diversity measure (normalized)\n",
    "    entropy = 0\n",
    "    \n",
    "    textLength = len(text)\n",
    "    if textLength <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        vocabulary = set(text)\n",
    "        for word in vocabulary:\n",
    "            p = text.count(word) / textLength\n",
    "\n",
    "            entropy -= p * math.log2(p)\n",
    "\n",
    "        return entropy / math.log2(textLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:48:17.297955Z",
     "start_time": "2019-07-08T16:48:17.278962Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def getBaseline(channel, video, length = None, messages = None): # use comment frequency to get baseline\n",
    "    # length is a hint for the length of this video\n",
    "    if not length: # check length is exist\n",
    "        with open(DATA_PATH + channel + \"/\" + str(video) + \"/info.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "            data = json.loads(data)\n",
    "        length = data['length']\n",
    "            \n",
    "    # messages is a hint for comment messages in this video\n",
    "    if not messages: # check messages is exist\n",
    "        messages = [[] for i in range(length)]\n",
    "        \n",
    "        messagePathList = glob.glob(DATA_PATH + channel + \"/\" + str(video) + \"/Message-*.json\")\n",
    "        for path in messagePathList:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            commentData = json.loads(data)['comments']\n",
    "            for comment in commentData:\n",
    "                offset = math.floor( comment['content_offset_seconds'] ) # get comment offset\n",
    "                \n",
    "                if offset >= length:\n",
    "                    break\n",
    "                    \n",
    "                messages[offset].append( comment['message']['body'] )\n",
    "                \n",
    "    commentFrequencyEachSecond = np.empty(length, dtype=int)\n",
    "    totalNumberOfMessages = 0\n",
    "    for i in range(length):\n",
    "        numberOfMessagesInThisSecond = len(messages[i])\n",
    "        \n",
    "        commentFrequencyEachSecond[i] = numberOfMessagesInThisSecond\n",
    "        totalNumberOfMessages += numberOfMessagesInThisSecond\n",
    "        \n",
    "    avgCommentFrequency = totalNumberOfMessages / length\n",
    "    \n",
    "    predictedFragment = { # initialize the object store what we predict\n",
    "        'macro': [0] * length,\n",
    "        'global': np.zeros(length, dtype=int),\n",
    "        'count': 0 # predicted fragment count for macro precision computing\n",
    "    }\n",
    "    strike = 0\n",
    "    for i in range(length):\n",
    "        if commentFrequencyEachSecond[i] > avgCommentFrequency:\n",
    "            strike += 1\n",
    "        else: # no strike or after a strike\n",
    "            if strike >= 5:\n",
    "                startIndex = i - strike # now i will be (the end of prediction + 1), so it can minus strike directly\n",
    "                \n",
    "                predictedFragment['count'] += 1\n",
    "                \n",
    "                predictedFragment['macro'][startIndex] = { # mark prediction in macro\n",
    "                    'duration': strike,\n",
    "                    'precision': []\n",
    "                }\n",
    "                \n",
    "                for global_index in range(startIndex, i): # mark prediction in global metrics\n",
    "                    predictedFragment['global'][global_index] = 1\n",
    "                    \n",
    "            strike = 0 # reset\n",
    "            \n",
    "        if i == length - 1 and strike >= 5: # check for the last second (use length instead of i to compute following data)\n",
    "            startIndex = length - strike\n",
    "            \n",
    "            predictedFragment['count'] += 1\n",
    "\n",
    "            predictedFragment['macro'][startIndex] = { # mark prediction in macro\n",
    "                'duration': strike,\n",
    "                'precision': []\n",
    "            }\n",
    "\n",
    "            for global_index in range(startIndex, length): # mark prediction in global metrics\n",
    "                predictedFragment['global'][global_index] = 1\n",
    "                \n",
    "    return predictedFragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:48:17.845119Z",
     "start_time": "2019-07-08T16:48:17.829105Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def detectLowDiversity(channel, video, length = None, messages = None):\n",
    "    # length is a hint for the length of this video\n",
    "    if not length: # check length is exist\n",
    "        with open(DATA_PATH + channel + \"/\" + str(video) + \"/info.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "            data = json.loads(data)\n",
    "        length = data['length']\n",
    "            \n",
    "    # messages is a hint for comment messages in this video\n",
    "    if not messages: # check messages is exist\n",
    "        messages = [[] for i in range(length)]\n",
    "        \n",
    "        messagePathList = glob.glob(DATA_PATH + channel + \"/\" + str(video) + \"/Message-*.json\")\n",
    "        for path in messagePathList:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            commentData = json.loads(data)['comments']\n",
    "            for comment in commentData:\n",
    "                offset = math.floor( comment['content_offset_seconds'] ) # get comment offset\n",
    "                \n",
    "                if offset >= length:\n",
    "                    break\n",
    "                    \n",
    "                messages[offset].append( comment['message']['body'] )\n",
    "                \n",
    "    predictedFragment = { # initialize the object store what we predict\n",
    "        'macro': [0] * length,\n",
    "        'global': np.zeros(length, dtype=int),\n",
    "        'count': 0 # predicted fragment count for macro precision computing\n",
    "    }\n",
    "    \n",
    "    startIndex = 0\n",
    "    while startIndex < length:\n",
    "        localMessage = ''\n",
    "        \n",
    "        for j in range(startIndex, startIndex + DIVERSITY_BASE_WINDOW):\n",
    "            if j >= length: # over video length\n",
    "                j -= 1 # resume for the lengh of predictedFragment['macro'] computing\n",
    "                break\n",
    "\n",
    "            localMessage += ' '.join(messages[j]) + ' '\n",
    "\n",
    "        localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "        localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "\n",
    "        score = normalized_shannon_entropy(localText)\n",
    "        \n",
    "        if score < DIVERSITY_THRESHOLD:\n",
    "            predictedFragment['count'] += 1\n",
    "            \n",
    "            predictedFragment['macro'][startIndex] = { # mark prediction in macro\n",
    "                'duration': j - startIndex + 1, # length of this fragment = j - i + 1\n",
    "                'precision': []\n",
    "            }\n",
    "            \n",
    "            for global_index in range(startIndex, j+1): # mark prediction in global metrics\n",
    "                predictedFragment['global'][global_index] = 1\n",
    "    \n",
    "        startIndex += DIVERSITY_BASE_WINDOW # move to next period\n",
    "    \n",
    "    return predictedFragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:48:18.405181Z",
     "start_time": "2019-07-08T16:48:18.386189Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def detectLowDiversityWithoutLowFrequency(channel, video, length = None, messages = None, totalNumberOfMessages = None):\n",
    "    # length is a hint for the length of this video\n",
    "    if not length: # check length is exist\n",
    "        with open(DATA_PATH + channel + \"/\" + str(video) + \"/info.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "            data = json.loads(data)\n",
    "        length = data['length']\n",
    "            \n",
    "    # messages is a hint for comment messages in this video\n",
    "    if not messages: # check messages is exist\n",
    "        messages = [[] for i in range(length)]\n",
    "        totalNumberOfMessages = 0 # if messages doesn't exist, then totalNumberOfMessages also will not exist\n",
    "        \n",
    "        messagePathList = glob.glob(DATA_PATH + channel + \"/\" + str(video) + \"/Message-*.json\")\n",
    "        for path in messagePathList:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            commentData = json.loads(data)['comments']\n",
    "            for comment in commentData:\n",
    "                offset = math.floor( comment['content_offset_seconds'] ) # get comment offset\n",
    "                \n",
    "                if offset >= length:\n",
    "                    break\n",
    "                    \n",
    "                messages[offset].append( comment['message']['body'] )\n",
    "                totalNumberOfMessages += 1\n",
    "                \n",
    "    predictedFragment = { # initialize the object store what we predict\n",
    "        'macro': [0] * length,\n",
    "        'global': np.zeros(length, dtype=int),\n",
    "        'count': 0 # predicted fragment count for macro precision computing\n",
    "    }\n",
    "    \n",
    "    avgMessageFrequency = totalNumberOfMessages / length\n",
    "    \n",
    "    startIndex = 0\n",
    "    while startIndex < length:\n",
    "        localMessage = ''\n",
    "        localFrequency = 0\n",
    "        \n",
    "        for j in range(startIndex, startIndex + DIVERSITY_BASE_WINDOW):\n",
    "            if j >= length: # over video length\n",
    "                j -= 1 # resume for the lengh of predictedFragment['macro'] computing\n",
    "                break\n",
    "\n",
    "            localMessage += ' '.join(messages[j]) + ' '\n",
    "            localFrequency += len(messages[j])\n",
    "\n",
    "        localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "        localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "\n",
    "        score = normalized_shannon_entropy(localText)\n",
    "        \n",
    "        if score < DIVERSITY_THRESHOLD:\n",
    "            localFrequency /= (j - startIndex + 1)\n",
    "            if localFrequency > avgMessageFrequency:\n",
    "                predictedFragment['count'] += 1\n",
    "\n",
    "                predictedFragment['macro'][startIndex] = { # mark prediction in macro\n",
    "                    'duration': j - startIndex + 1, # length of this fragment = j - i + 1\n",
    "                    'precision': []\n",
    "                }\n",
    "\n",
    "                for global_index in range(startIndex, j+1): # mark prediction in global metrics\n",
    "                    predictedFragment['global'][global_index] = 1\n",
    "        \n",
    "        startIndex += DIVERSITY_BASE_WINDOW # move to next period\n",
    "    \n",
    "    return predictedFragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:48:19.014990Z",
     "start_time": "2019-07-08T16:48:18.995992Z"
    },
    "code_folding": [
     0,
     2,
     9,
     26
    ]
   },
   "outputs": [],
   "source": [
    "def detectLowDiversityExpand(channel, video, length = None, messages = None): # now only expand the tail of fragment\n",
    "    # length is a hint for the length of this video\n",
    "    if not length: # check length is exist\n",
    "        with open(DATA_PATH + channel + \"/\" + str(video) + \"/info.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "            data = json.loads(data)\n",
    "        length = data['length']\n",
    "            \n",
    "    # messages is a hint for comment messages in this video\n",
    "    if not messages: # check messages is exist\n",
    "        messages = [[] for i in range(length)]\n",
    "        \n",
    "        messagePathList = glob.glob(DATA_PATH + channel + \"/\" + str(video) + \"/Message-*.json\")\n",
    "        for path in messagePathList:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            commentData = json.loads(data)['comments']\n",
    "            for comment in commentData:\n",
    "                offset = math.floor( comment['content_offset_seconds'] ) # get comment offset\n",
    "                \n",
    "                if offset >= length:\n",
    "                    break\n",
    "                    \n",
    "                messages[offset].append( comment['message']['body'] )\n",
    "                \n",
    "    predictedFragment = { # initialize the object store what we predict\n",
    "        'macro': [0] * length,\n",
    "        'global': np.zeros(length, dtype=int),\n",
    "        'count': 0 # predicted fragment count for macro precision computing\n",
    "    }\n",
    "    \n",
    "    startIndex = 0\n",
    "    while startIndex < length:\n",
    "        localMessage = ''\n",
    "        numberOfMessages = 0\n",
    "        \n",
    "        for j in range(startIndex, startIndex + DIVERSITY_BASE_WINDOW):\n",
    "            if j >= length: # over video length\n",
    "                j -= 1 # resume for the lengh of predictedFragment['macro'] computing\n",
    "                break\n",
    "\n",
    "            localMessage += ' '.join(messages[j]) + ' '\n",
    "            numberOfMessages += len(messages[j])\n",
    "        \n",
    "        localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "        localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "\n",
    "        score = normalized_shannon_entropy(localText)\n",
    "        \n",
    "        endIndex = j # WARNING!! j is out of scope\n",
    "        duration = endIndex - startIndex + 1\n",
    "        # Detect if it is highlight\n",
    "        if score < DIVERSITY_THRESHOLD:            \n",
    "            localFrequency = numberOfMessages / duration\n",
    "            \n",
    "            RESHARP_WINDOW = 5\n",
    "            for i in range(endIndex + 1, endIndex + (MAX_CLIP_LENGTH - DIVERSITY_BASE_WINDOW + 1), RESHARP_WINDOW):\n",
    "                if i >= length: # over video length\n",
    "                    break\n",
    "                \n",
    "                for j in range(i, i+RESHARP_WINDOW):\n",
    "                    if j >= length: # over video length\n",
    "                        j -= 1 # resume for the duration computing\n",
    "                        break\n",
    "                    \n",
    "                    localMessage += ' '.join(messages[j]) + ' '\n",
    "                    numberOfMessages += len(messages[j])\n",
    "                \n",
    "                localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "                localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "                \n",
    "                newScore = normalized_shannon_entropy(localText)\n",
    "                \n",
    "                newEndIndex = j # WARNING!! j is out of scope\n",
    "                newDuration = newEndIndex - startIndex + 1\n",
    "                if numberOfMessages != 0 and (newScore / (numberOfMessages/ newDuration) < score / localFrequency):\n",
    "                    duration = newDuration\n",
    "                    endIndex = newEndIndex\n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "            predictedFragment['count'] += 1\n",
    "\n",
    "            predictedFragment['macro'][startIndex] = { # mark prediction in macro\n",
    "                'duration': duration,\n",
    "                'precision': []\n",
    "            }\n",
    "\n",
    "            for global_index in range(startIndex, endIndex+1): # mark prediction in global metrics\n",
    "                predictedFragment['global'][global_index] = 1\n",
    "        \n",
    "        startIndex += duration # move to next period\n",
    "    \n",
    "    return predictedFragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:48:19.650813Z",
     "start_time": "2019-07-08T16:48:19.625823Z"
    },
    "code_folding": [
     0,
     2,
     9,
     28
    ]
   },
   "outputs": [],
   "source": [
    "def detectLowDiversityWithoutLowFrequencyExpand(channel, video, length = None, messages = None, totalNumberOfMessages = None): # now only expand the tail of fragment\n",
    "    # length is a hint for the length of this video\n",
    "    if not length: # check length is exist\n",
    "        with open(DATA_PATH + channel + \"/\" + str(video) + \"/info.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "            data = json.loads(data)\n",
    "        length = data['length']\n",
    "            \n",
    "    # messages is a hint for comment messages in this video\n",
    "    if not messages: # check messages is exist\n",
    "        messages = [[] for i in range(length)]\n",
    "        totalNumberOfMessages = 0 # if messages doesn't exist, then totalNumberOfMessages also will not exist\n",
    "        \n",
    "        messagePathList = glob.glob(DATA_PATH + channel + \"/\" + str(video) + \"/Message-*.json\")\n",
    "        for path in messagePathList:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "                data = file.read()\n",
    "                \n",
    "            commentData = json.loads(data)['comments']\n",
    "            for comment in commentData:\n",
    "                offset = math.floor( comment['content_offset_seconds'] ) # get comment offset\n",
    "                \n",
    "                if offset >= length:\n",
    "                    break\n",
    "                    \n",
    "                messages[offset].append( comment['message']['body'] )\n",
    "                totalNumberOfMessages += 1\n",
    "                \n",
    "    predictedFragment = { # initialize the object store what we predict\n",
    "        'macro': [0] * length,\n",
    "        'global': np.zeros(length, dtype=int),\n",
    "        'count': 0 # predicted fragment count for macro precision computing\n",
    "    }\n",
    "    \n",
    "    avgMessageFrequency = totalNumberOfMessages / length\n",
    "    \n",
    "    startIndex = 0\n",
    "    while startIndex < length:\n",
    "        localMessage = ''\n",
    "        numberOfMessages = 0\n",
    "        \n",
    "        for j in range(startIndex, startIndex + DIVERSITY_BASE_WINDOW):\n",
    "            if j >= length: # over video length\n",
    "                j -= 1 # resume for the lengh of predictedFragment['macro'] computing\n",
    "                break\n",
    "\n",
    "            localMessage += ' '.join(messages[j]) + ' '\n",
    "            numberOfMessages += len(messages[j])\n",
    "        \n",
    "        localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "        localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "\n",
    "        score = normalized_shannon_entropy(localText)\n",
    "        \n",
    "        endIndex = j # WARNING!! j is out of scope\n",
    "        duration = endIndex - startIndex + 1\n",
    "        # Detect if it is highlight\n",
    "        if score < DIVERSITY_THRESHOLD:            \n",
    "            localFrequency = numberOfMessages / duration\n",
    "            if localFrequency > avgMessageFrequency:\n",
    "                RESHARP_WINDOW = 5\n",
    "                for i in range(endIndex + 1, endIndex + (MAX_CLIP_LENGTH - DIVERSITY_BASE_WINDOW + 1), RESHARP_WINDOW):\n",
    "                    if i >= length: # over video length\n",
    "                        break\n",
    "\n",
    "                    for j in range(i, i+RESHARP_WINDOW):\n",
    "                        if j >= length: # over video length\n",
    "                            j -= 1 # resume for the duration computing\n",
    "                            break\n",
    "\n",
    "                        localMessage += ' '.join(messages[j]) + ' '\n",
    "                        numberOfMessages += len(messages[j])\n",
    "\n",
    "                    localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "                    localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "\n",
    "                    newScore = normalized_shannon_entropy(localText)\n",
    "\n",
    "                    newEndIndex = j # WARNING!! j is out of scope\n",
    "                    newDuration = newEndIndex - startIndex + 1\n",
    "                    if numberOfMessages != 0 and (newScore / (numberOfMessages/ newDuration) < score / localFrequency):\n",
    "                        duration = newDuration\n",
    "                        endIndex = newEndIndex\n",
    "                    else:\n",
    "                        break\n",
    "\n",
    "                predictedFragment['count'] += 1\n",
    "\n",
    "                predictedFragment['macro'][startIndex] = { # mark prediction in macro\n",
    "                    'duration': duration,\n",
    "                    'precision': []\n",
    "                }\n",
    "\n",
    "                for global_index in range(startIndex, endIndex+1): # mark prediction in global metrics\n",
    "                    predictedFragment['global'][global_index] = 1\n",
    "        \n",
    "        startIndex += duration # move to next period\n",
    "    \n",
    "    return predictedFragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "messageEachSecond = [''] * videoLength\n",
    "\n",
    "for i in range(1, numberOfMessage + 1):\n",
    "    with open(\"../TwitchHighlightCrawler/vod/lirik/389178879/Message-\" + str(i) + \".json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        messages = file.read()\n",
    "        \n",
    "    messages = json.loads(messages)['comments']\n",
    "    for message in messages:\n",
    "        offset = math.floor( message['content_offset_seconds'] )\n",
    "        \n",
    "        if offset >= videoLength:\n",
    "            break\n",
    "        \n",
    "        if messageEachSecond[offset]:\n",
    "            messageEachSecond[offset] += ' ' + message['message']['body']\n",
    "        else:\n",
    "            messageEachSecond[offset] = message['message']['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "predictedFragment = {\n",
    "    'macro': [0] * videoLength,\n",
    "    'micro': np.zeros(videoLength, dtype=int),\n",
    "    'count': 0 # predicted fragment count for macro precision computing # 356\n",
    "}\n",
    "\n",
    "i = 0\n",
    "while i < videoLength:\n",
    "    localMessage = ''\n",
    "    localFQ = 0\n",
    "    \n",
    "    for j in range(i, i+30):\n",
    "        if j >= videoLength: # over video length\n",
    "            j -= 1 # resume for lengh of predictedFragment['macro'] computing\n",
    "            break\n",
    "            \n",
    "        localMessage += messageEachSecond[j] + ' '\n",
    "        localFQ += commentFQ[j]\n",
    "        \n",
    "    localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "    localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "    \n",
    "    score = normalized_shannon_entropy(localText)\n",
    "    \n",
    "    if score < 0.835:\n",
    "        if localFQ / (j - i + 1) > 2.526795059660875:\n",
    "            '''scoreList = []\n",
    "            localMessage = '' # reset\n",
    "            localFQ = 0 # reset\n",
    "            shape_window = 5\n",
    "            for macro_index in range(i, i+30, shape_window):\n",
    "                for macro_seek in range(macro_index, macro_index + shape_window):\n",
    "                    localMessage += messageEachSecond[j] + ' '\n",
    "                    localFQ += commentFQ[j]\n",
    "                    \n",
    "                localTokens = tknzr.tokenize(localMessage) # tokenization\n",
    "                localText = nltk.text.Text(localTokens) # convert tokens to NLTK text\n",
    "                \n",
    "                scoreList.append({\n",
    "                    'frequency': localFQ / (macro_seek - i + 1),\n",
    "                    'diversity': normalized_shannon_entropy(localText)\n",
    "                })'''\n",
    "            \n",
    "            predictedFragment['count'] += 1\n",
    "            \n",
    "            predictedFragment['macro'][i] = { # mark prediction in macro\n",
    "                'duration': j - i + 1, # length of this fragment = j - i + 1\n",
    "                'precision': []\n",
    "            }\n",
    "            \n",
    "            for micro_index in range(i, j+1): # mark prediction in micro\n",
    "                predictedFragment['micro'][micro_index] = 1\n",
    "    \n",
    "    i += 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T16:51:20.907731Z",
     "start_time": "2019-07-08T16:51:20.805763Z"
    },
    "code_folding": [
     0,
     84,
     176
    ]
   },
   "outputs": [],
   "source": [
    "def local_score(clipDataList, predict, numberOfPredictedFragment):\n",
    "    localPrecision = 0\n",
    "    localRecall = 0\n",
    "    \n",
    "    videoLength = len(predict)\n",
    "    \n",
    "    for clip in clipDataList:\n",
    "        recall = 0\n",
    "        overlapTime = 0 # for local recall computing\n",
    "\n",
    "        endOfClip = clip['offset'] + clip['duration'] # not real video end timeline point\n",
    "\n",
    "        for i in range(clip['offset'] - (MAX_CLIP_LENGTH-1), clip['offset'] - MIN_CLIP_LENGTH + 1): # (offset - 59) <= prediction <= (offset - 5) # eg. offset = 85, duration = 10, 26~80\n",
    "            if predict[i] and (i + predict[i]['duration']) > clip['offset']: # Simplify from (i + (predict[i]['duration']-1)) >= clip['offset']\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset'] # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip:\n",
    "                    overlap -= (endOfPrediction - endOfClip) # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'] - MIN_CLIP_LENGTH + 1, clip['offset']): # (offset - 4(less than MIN_CLIP_LENGTH)) <= prediction < offset # 81~84\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset']; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip: # predicted fragment is larger than clip\n",
    "                    overlap -= (endOfPrediction - endOfClip); # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'], endOfClip): # offset <= prediction < (offset + duration) # 85~94\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfClip - i; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction < endOfClip: # predicted fragment is smaller than clip\n",
    "                    overlap -= endOfClip - endOfPrediction\n",
    "\n",
    "                # precision\n",
    "                predict[i]['precision'].append( overlap/predict[i]['duration'] )\n",
    "                # local recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                overlapTime += 1\n",
    "\n",
    "        if overlapTime:\n",
    "            recall /= overlapTime\n",
    "            localRecall += recall\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if predict[i]: # check have predicted fragment\n",
    "            if len(predict[i]['precision']): # the fragment has overlap\n",
    "                precision = 0 # for local precision computing\n",
    "\n",
    "                for singlePrecisionValue in predict[i]['precision']:\n",
    "                    # local precision\n",
    "                    precision += singlePrecisionValue\n",
    "                precision /= len(predict[i]['precision'])\n",
    "\n",
    "                localPrecision += precision\n",
    "\n",
    "    localPrecision /= numberOfPredictedFragment\n",
    "    localRecall /= len(clipDataList)\n",
    "    F1 = (2 * localPrecision * localRecall) / (localPrecision + localRecall)\n",
    "    print(str(localPrecision) + ' ' + str(localRecall) + ' ' + str(F1))\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'F1': F1\n",
    "    }\n",
    "    \n",
    "def macro_score(clipDataList, predict):\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    macroF1 = 0\n",
    "    \n",
    "    videoLength = len(predict)\n",
    "    \n",
    "    for clip in clipDataList:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        F1 = 0\n",
    "        \n",
    "        overlapTime = 0\n",
    "\n",
    "        endOfClip = clip['offset'] + clip['duration'] # not real video end timeline point\n",
    "\n",
    "        for i in range(clip['offset'] - (MAX_CLIP_LENGTH-1), clip['offset'] - MIN_CLIP_LENGTH + 1): # (offset - 59) <= prediction <= (offset - 5) # eg. offset = 85, duration = 10, 26~80\n",
    "            if predict[i] and (i + predict[i]['duration']) > clip['offset']: # Simplify from (i + (predict[i]['duration']-1)) >= clip['offset']\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset'] # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip:\n",
    "                    overlap -= (endOfPrediction - endOfClip) # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'] - MIN_CLIP_LENGTH + 1, clip['offset']): # (offset - 4(less than MIN_CLIP_LENGTH)) <= prediction < offset # 81~84\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfPrediction - clip['offset']; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction > endOfClip: # predicted fragment is larger than clip\n",
    "                    overlap -= (endOfPrediction - endOfClip); # remove the part over than the end of ground true\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        for i in range(clip['offset'], endOfClip): # offset <= prediction < (offset + duration) # 85~94\n",
    "            if predict[i]: # no need to check if it overlap the ground truth period, it must be in the period\n",
    "                endOfPrediction = i + predict[i]['duration']\n",
    "                overlap = endOfClip - i; # compute overlap seconds\n",
    "\n",
    "                if endOfPrediction < endOfClip: # predicted fragment is smaller than clip\n",
    "                    overlap -= endOfClip - endOfPrediction\n",
    "\n",
    "                # precision\n",
    "                singlePrecisionVlaue = overlap / predict[i]['duration']\n",
    "                precision += singlePrecisionVlaue\n",
    "                # recall\n",
    "                singleRecallValue = overlap / clip['duration']\n",
    "                recall += singleRecallValue\n",
    "                # F1\n",
    "                singleF1Value = (2 * singlePrecisionVlaue * singleRecallValue) / (singlePrecisionVlaue + singleRecallValue)\n",
    "                F1 += singleF1Value\n",
    "                \n",
    "                overlapTime += 1\n",
    "\n",
    "        if overlapTime:\n",
    "            precision /= overlapTime\n",
    "            recall /= overlapTime\n",
    "            F1 /= overlapTime\n",
    "            \n",
    "            macroPrecision += precision\n",
    "            macroRecall += recall\n",
    "            macroF1 += F1\n",
    "    \n",
    "    numberOfAnswer = len(clipDataList)\n",
    "    \n",
    "    macroPrecision /= numberOfAnswer\n",
    "    macroRecall /= numberOfAnswer\n",
    "    macroF1 /= numberOfAnswer  \n",
    "    print(str(macroPrecision) + ' ' + str(macroRecall) + ' ' + str(macroF1))\n",
    "    \n",
    "def global_score(groundTruth, predict):\n",
    "    videoLength = len(groundTruth)\n",
    "    \n",
    "    # normal score\n",
    "    overlap = 0\n",
    "    totalClipSeconds = 0 # WARNING!! we can count this value when computing local score\n",
    "    totalPredictSeconds = 0\n",
    "    \n",
    "    # weighted score\n",
    "    weightedOverlap = 0\n",
    "    totalWeightedClipSeconds = 0 # WARNING!! we can count this value when computing local score\n",
    "    totalWeightedPredictSeconds = 0\n",
    "    \n",
    "    for i in range(videoLength):\n",
    "        if groundTruth[i]:\n",
    "            totalClipSeconds += 1\n",
    "            totalWeightedClipSeconds += groundTruth[i]\n",
    "            \n",
    "            if predict[i]:\n",
    "                totalPredictSeconds += 1\n",
    "                totalWeightedPredictSeconds += groundTruth[i]\n",
    "                \n",
    "                overlap += 1\n",
    "                weightedOverlap += groundTruth[i]\n",
    "        elif predict[i]:\n",
    "            totalPredictSeconds += 1\n",
    "            totalWeightedPredictSeconds += 1 # no clip on this second, so weight is 1\n",
    "                \n",
    "    precision = overlap / totalPredictSeconds\n",
    "    recall = overlap / totalClipSeconds\n",
    "    F1 = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    weightedPrecision = weightedOverlap / totalWeightedPredictSeconds\n",
    "    weightedRecall = weightedOverlap / totalWeightedClipSeconds\n",
    "    weightedF1 = (2 * weightedPrecision * weightedRecall) / (weightedPrecision + weightedRecall)\n",
    "    print(str(precision) + ' ' + str(recall) + ' ' + str(F1))\n",
    "    print(str(weightedPrecision) + ' ' + str(weightedRecall) + ' ' + str(weightedF1))\n",
    "    \n",
    "    return {\n",
    "        'normal': {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'F1': F1\n",
    "        },\n",
    "        'weighted': {\n",
    "            'precision': weightedPrecision,\n",
    "            'recall': weightedRecall,\n",
    "            'F1': weightedF1\n",
    "        }\n",
    "    }\n",
    "\n",
    "def evaluation(channel, video, predict):\n",
    "    global_answer = np.zeros(len(predict['macro']), dtype=int) # WARNING!! use dependent data len(predict['macro'])\n",
    "    \n",
    "    clipList = os.listdir(DATA_PATH + channel + '/'+ video +'/clip')\n",
    "    clipDataList = [] # ground true for loacl & macro\n",
    "    for clip in clipList:\n",
    "        with open(DATA_PATH + channel + '/'+ video +'/clip/' + clip, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = file.read()\n",
    "\n",
    "        data = json.loads(data)\n",
    "        \n",
    "        # generate ground true for local & macro evaluation metrics\n",
    "        clipDataList.append({\n",
    "            'offset': data['vod']['offset'],\n",
    "            'duration': math.ceil( data['duration'] ) # length of ground true clip\n",
    "        })\n",
    "        \n",
    "        # generate ground true for global evaluation metrics\n",
    "        for i in range(clipDataList[-1]['offset'], clipDataList[-1]['offset'] + clipDataList[-1]['duration']):\n",
    "            global_answer[i] += 1\n",
    "    \n",
    "    print(predict['count'])\n",
    "    local_score(clipDataList, predict['macro'], predict['count'])\n",
    "    #macro_score(clipDataList, predict['macro'])\n",
    "    global_score(global_answer, predict['global'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31302776542041605\n",
      "0.46581959122317684\n"
     ]
    }
   ],
   "source": [
    "# 'lirik', '389178879'\n",
    "# DIVERSITY_THRESHOLD < 0.835\n",
    "\n",
    "# getBaseline\n",
    "515\n",
    "0.31255464027255025 0.2876522567032966 0.299586852701908\n",
    "0.39937353171495693 0.2872430301323571 0.33415233415233414\n",
    "#0.6573413100600842 0.2876522567032966 0.3614468198549178\n",
    "0.7179628608200037 0.40441176470588236 0.5173898641934416\n",
    "\n",
    "# detectLowDiversity\n",
    "356\n",
    "0.2628395718152477 0.4893461761926615 0.34198877008915485\n",
    "0.3429000187582067 0.5147845677274008 0.41161900472866464\n",
    "#0.45959520239879975 0.4893461761926615 0.46529794868318325\n",
    "0.6652331804281345 0.7208989229494615 0.691948310139165\n",
    "\n",
    "# detectLowDiversityWithoutLowFrequency\n",
    "253\n",
    "0.31302776542041605 0.48823340732165216 0.3814751486696332\n",
    "0.40737812911725957 0.43537031822021965 0.4209093384154642\n",
    "#0.45743794769281965 0.48823340732165216 0.46380044758987177\n",
    "0.7378940621175922 0.6557062966031483 0.6943766621884683\n",
    "\n",
    "# detectLowDiversityReshap\n",
    "291\n",
    "0.2607106187891543 0.6286878185352636 0.3685762945314142\n",
    "0.3512001443782711 0.5480146437623205 0.4280686317641883\n",
    "#0.45190903466015914 0.6286878185352636 0.5041619874828696\n",
    "0.6524051244863428 0.6987883181441591 0.6748006100457534\n",
    "\n",
    "# detectLowDiversityWithoutLowFrequencyReshap\n",
    "198\n",
    "0.3020856113494304 0.6081953340588494 0.40367110887207064\n",
    "0.4196286472148541 0.4455083075190087 0.4321813959841552\n",
    "#0.45583974787498033 0.6081953340588494 0.5007325842535026\n",
    "0.7422243166823751 0.6524440762220381 0.6944444444444444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 'lirik', '389178879'\n",
    "# DIVERSITY_THRESHOLD < 0.8\n",
    "\n",
    "# getBaseline\n",
    "515\n",
    "0.31255464027255025 0.2876522567032966 0.299586852701908\n",
    "0.39937353171495693 0.2872430301323571 0.33415233415233414\n",
    "0.7179628608200037 0.40441176470588236 0.5173898641934416\n",
    "\n",
    "# detectLowDiversity\n",
    "229\n",
    "0.28183306622319965 0.43600120533922376 0.34236191122585213\n",
    "0.37098657326328077 0.3579273444100253 0.3643399742009459\n",
    "0.7054803881372147 0.5345898922949461 0.608260177929653\n",
    "\n",
    "# detectLowDiversityWithoutLowFrequency\n",
    "166\n",
    "0.32917472583340396 0.4344338179064545 0.37454958846252523\n",
    "0.43775100401606426 0.3069557871022247 0.3608674060585995\n",
    "0.7699827487061529 0.48534589892294944 0.595394632364618\n",
    "\n",
    "# detectLowDiversityReshap\n",
    "192\n",
    "0.2740116097248532 0.43936409740730725 0.33752442754146034\n",
    "0.3683712121212121 0.38341312306392566 0.3757416862149855\n",
    "0.6500524658971668 0.4490990057995029 0.5312059778281374\n",
    "\n",
    "# detectLowDiversityWithoutLowFrequencyReshap\n",
    "143\n",
    "0.31189666808158234 0.40969243856628224 0.35416750433124056\n",
    "0.4261029411764706 0.3263869332582371 0.36963801626534837\n",
    "0.7202007528230866 0.41611433305716655 0.5274696422710863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 'lirik', '389178879'\n",
    "# DIVERSITY_THRESHOLD < 0.4\n",
    "\n",
    "# getBaseline\n",
    "515\n",
    "0.31255464027255025 0.2876522567032966 0.299586852701908\n",
    "0.39937353171495693 0.2872430301323571 0.33415233415233414\n",
    "0.7179628608200037 0.40441176470588236 0.5173898641934416\n",
    "\n",
    "# detectLowDiversity\n",
    "379\n",
    "0.2533532653462485 0.4943392632744201 0.33501061397651916\n",
    "0.33033826638477803 0.5280202759785976 0.40641595318088225\n",
    "0.6486573924296344 0.7267502071251035 0.6854868250750934\n",
    "\n",
    "# detectLowDiversityWithoutLowFrequency\n",
    "269\n",
    "0.2976308227436131 0.4896959067560582 0.37023662518000683\n",
    "0.3876084262701363 0.4404393128696142 0.412338518323227\n",
    "0.7200158631239023 0.6580882352941176 0.6876606336065795\n",
    "\n",
    "# detectLowDiversityReshap\n",
    "297\n",
    "0.25854672514892657 0.631986448774863 0.3669667373519406\n",
    "0.3494538407329105 0.5585750492818924 0.42993388967161594\n",
    "0.6480484201496449 0.7041217895608948 0.6749224469537163\n",
    "\n",
    "# detectLowDiversityWithoutLowFrequencyReshap\n",
    "204\n",
    "0.2963177650150011 0.609231027051812 0.39871065567158764\n",
    "0.41049935979513447 0.45142213460996905 0.4299892703862661\n",
    "0.7331169207582169 0.6548777961888981 0.6917922489948856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31302776542041605\n",
      "0.48823340732165216\n",
      "0.40737812911725957\n",
      "0.43537031822021965\n"
     ]
    }
   ],
   "source": [
    "evaluation('lirik', '389178879', predictedFragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T17:04:55.329845Z",
     "start_time": "2019-07-08T17:04:50.193724Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "0.2963177650150011 0.609231027051812 0.39871065567158764\n",
      "0.41049935979513447 0.45142213460996905 0.4299892703862661\n",
      "0.7331169207582169 0.6548777961888981 0.6917922489948856\n"
     ]
    }
   ],
   "source": [
    "#kk = getBaseline('lirik', '389178879')\n",
    "#kk = detectLowDiversity('lirik', '389178879')\n",
    "#kk = detectLowDiversityWithoutLowFrequency('lirik', '389178879')\n",
    "#kk = detectLowDiversityReshap('lirik', '389178879')\n",
    "#kk = detectLowDiversityWithoutLowFrequencyReshap('lirik', '389178879')\n",
    "#print(kk['count'])\n",
    "evaluation('lirik', '389178879', kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "356\n",
    "253\n",
    "\n",
    "print(localPrecision) # 0.2628395718152477 0.31302776542041605\n",
    "print(localRecall) # 0.4646896538639685 0.46581959122317684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
